{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":260,"sourceType":"datasetVersion","datasetId":122}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install scikit-posthocs","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T13:10:50.162708Z","iopub.execute_input":"2024-05-08T13:10:50.163516Z","iopub.status.idle":"2024-05-08T13:11:05.238434Z","shell.execute_reply.started":"2024-05-08T13:10:50.163477Z","shell.execute_reply":"2024-05-08T13:11:05.236894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pvlib #Required for Solar Features","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T13:11:05.241274Z","iopub.execute_input":"2024-05-08T13:11:05.241657Z","iopub.status.idle":"2024-05-08T13:11:20.236206Z","shell.execute_reply.started":"2024-05-08T13:11:05.241623Z","shell.execute_reply":"2024-05-08T13:11:20.234688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install meteostat #Weather data python API library","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T13:11:20.237756Z","iopub.execute_input":"2024-05-08T13:11:20.238637Z","iopub.status.idle":"2024-05-08T13:11:35.185513Z","shell.execute_reply.started":"2024-05-08T13:11:20.238596Z","shell.execute_reply":"2024-05-08T13:11:35.183975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install distfit","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T13:11:35.190644Z","iopub.execute_input":"2024-05-08T13:11:35.191107Z","iopub.status.idle":"2024-05-08T13:11:50.55167Z","shell.execute_reply.started":"2024-05-08T13:11:35.191067Z","shell.execute_reply":"2024-05-08T13:11:50.550428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install xgboost","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T13:11:50.553822Z","iopub.execute_input":"2024-05-08T13:11:50.554199Z","iopub.status.idle":"2024-05-08T13:12:05.476081Z","shell.execute_reply.started":"2024-05-08T13:11:50.554165Z","shell.execute_reply":"2024-05-08T13:12:05.474692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport time\n\nfrom scipy.stats import kruskal\nfrom scikit_posthocs import posthoc_nemenyi\nfrom statsmodels.stats.multitest import multipletests\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import TimeSeriesSplit \nfrom sklearn.metrics import mean_squared_error\n\nimport xgboost as xgb\n\nimport pvlib\nfrom pvlib.location import Location\nfrom pvlib import clearsky, solarposition,tracking\nfrom meteostat import Hourly,Point\nfrom distfit import distfit\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T13:12:05.478466Z","iopub.execute_input":"2024-05-08T13:12:05.478854Z","iopub.status.idle":"2024-05-08T13:12:05.500044Z","shell.execute_reply.started":"2024-05-08T13:12:05.478818Z","shell.execute_reply":"2024-05-08T13:12:05.498623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Veri Seti Hakkında Genel Bilgiler**\n\nBu arşiv, Aralık 2006 ile Kasım 2010 (47 ay) arasında Sceaux'da (Paris'e 7 km, Fransa) bulunan bir evde toplanan 2075259 ölçümü içermektedir.\n\n\n1.date: gg/aa/yyyy biçiminde tarih\n\n2.time: hh:mm:ss formatında zaman\n\n3.global_active_power: hane halkı küresel dakika ortalama aktif güç (kilowatt cinsinden)\n\n4.global_reactive_power: hane halkı küresel dakika ortalama reaktif gücü (kilowatt cinsinden)\n\n5.voltaj: dakika ortalamalı voltaj (volt cinsinden)\n\n6.global_intensity: hane halkı küresel dakika ortalamalı akım yoğunluğu (amper cinsinden)\n\n7.sub_metering_1: 1 numaralı enerji alt ölçümü (watt-saat aktif enerji cinsinden). Esas olarak bir bulaşık makinesi, bir fırın ve bir mikrodalga fırın içeren mutfağa karşılık gelir (ocaklar elektrikli değil gazla çalışır).\n\n8.sub_metering_2: 2 numaralı enerji alt ölçümü (watt-saat aktif enerji cinsinden). Bir çamaşır makinesi, bir çamaşır kurutma makinesi, bir buzdolabı ve bir ışık içeren çamaşır odasına karşılık gelir.\n\n9.sub_metering_3: 3 numaralı enerji alt ölçümü (watt-saat aktif enerji olarak). Bir elektrikli su ısıtıcısına ve bir klimaya karşılık gelir.\n\n----------------https://elektrikportal.com/aktif-reaktif-gorunur-guc-nedir/------------------------------------------------------\n\n**Bazı Terimlerin Açıklamaları:**\n- **Aktif Güç:** Elektrik devrelerinde alıcılar tarafından şebekeden çekilen faydalı, işe yarayan güce Aktif Güç denir. Örnek olarak; Elektrik akımının, Isıtıcılarda ısıya, motorlarda harekete, aydınlatma armatürlerinde ise ışığa dönüşürler.Bunlar faydalı yani işe yarayan Aktif güç örnekleridir.\n\n- **Reaktif Güç:** Elektrik devrelerinde kaynaktan çekilip, sonradan tekrar kaynağa geri dönen güce Reaktif Güç denir. Motorlarda ve bobinli devrelerde manyetik alanın, kondansatörlerde gerekli elektrik alanının oluşumunu sağlar.Bu alanların oluşumu için kaynaktan çekilen güç alanlar yok olurken tekrar kaynağa iade edilir. Reaktif gücün alıcılarda karşılığı olmadığından kör güç olarakta bilinmektedir.Gerekli önlemler alınmazsa şebekede gereksiz yere kapasite işgal ederler. Reaktif güç, Volt Amper Reaktif kelimelerinin kısaltması olan VAR birimi ile gösterilir.\n- **Kısaca Aktif, Reaktif Güç**\n    - Bir yük tarafından harcanan güce aktif güç denir. Aktif güç P harfi ile sembolize edilir.\n    - Reaktif özelliklerinden dolayı yalnızca emilen ve yükte geri dönen güç , reaktif güç olarak adlandırılır.\n \n -------------------------------------------------------------------------------------------------------------------\n \n**About Dataset**\n\n This dataset contains 2075259 measurements collected between December 2006 and November 2010 (47 months) in a house located in Sceaux (7 km from Paris, France).\n\n\n1.date: date in dd/mm/yyyy format\n\n2.time: time in hh:mm:ss format\n\n3.global_active_power: household global minute average active power (in kilowatts)\n\n4.global_reactive_power: household global minute average reactive power (in kilowatts)\n\n5th voltage: minute averaged voltage (in volts)\n\n6.global_intensity: household global minute-averaged current intensity (in amperes)\n\n7.sub_metering_1: Energy sub-metering number 1 (in watt-hours of active energy). It mainly corresponds to the kitchen, which includes a dishwasher, an oven and a microwave oven (hobs are gas, not electric).\n\n8.sub_metering_2: Energy submetering number 2 (in watt-hours of active energy). Corresponds to the laundry room containing a washing machine, a tumble dryer, a refrigerator and a light.\n\n9.sub_metering_3: Energy submetering number 3 (in watt-hours of active energy). Corresponds to an electric water heater and an air conditioner.\n\n**Explanations of Some Terms:**\n\n\n- **Active Power:** The useful, useful power drawn from the network by the receivers in electrical circuits is called Active Power. For example; Electric current is transformed into heat in heaters, into heat in heaters, into motion in motors, and into light in lighting fixtures.\n\n- **Reactive Power:** In electrical circuits, the power that is drawn from the source and then returned to the source is called Reactive Power. It provides the formation of the magnetic field in motors and coil circuits and the required electric field in capacitors. The power drawn from the source for the formation of these fields is returned to the source again as the fields disappear. Reactive power is also known as blind power because it has no equivalent in receivers. If necessary precautions are not taken, they occupy unnecessary capacity in the network. Reactive power is indicated by the VAR unit, which is the abbreviation of the words Volt Ampere Reactive.\n- **In short Active, Reactive Power**\n\n    - The power dissipated by a load is called active power. Active power is symbolized by the letter P.\n\n    - Power that is only absorbed and returned in the load due to its reactive properties is called reactive power.\n    ","metadata":{}},{"cell_type":"markdown","source":"# CONFIGURATION","metadata":{}},{"cell_type":"code","source":"class config:\n    dir_dataset = \"/kaggle/input/electric-power-consumption-data-set/household_power_consumption.txt\"\n    \n    use_pca = True\n    sum_sub_meterings = True\n    add_moving_averages = True\n    change_2008August_values = False\n    \n    n_splits = 5","metadata":{"execution":{"iopub.status.busy":"2024-05-08T13:12:05.501842Z","iopub.execute_input":"2024-05-08T13:12:05.502222Z","iopub.status.idle":"2024-05-08T13:12:05.50956Z","shell.execute_reply.started":"2024-05-08T13:12:05.502178Z","shell.execute_reply":"2024-05-08T13:12:05.508644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UTILS","metadata":{}},{"cell_type":"code","source":"def preprocessing(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \n    \"\"\"\n        This fuction does some preprocecessing operation on dataset\n    \n    \"\"\"\n    #Create list for float data type columns \n    float_columns = [\"Global_active_power\",\n                    \"Global_reactive_power\",\n                    \"Voltage\",\n                    \"Global_intensity\",\n                    \"Sub_metering_1\",\n                    \"Sub_metering_2\",\n                    \"Sub_metering_3\"]\n    #Change ? ve \"nan\" to np.nan \n    dataframe[float_columns] = dataframe[float_columns].replace([\"?\", \"nan\"], np.nan)\n    \n    #NaN değerleri bir önceki değerler ile değiştirmek\n    #dataframe[float_columns] = dataframe[float_columns].fillna(method = \"ffill\")\n    \n    dataframe = dataframe.dropna()\n    \n    #Change data type to float\n    dataframe[float_columns] = dataframe[float_columns].astype(float)\n    \n    #Merge Date and Time columns\n    dataframe[\"Datetime\"] = dataframe[\"Date\"] + \" \" + dataframe[\"Time\"]\n    #Change Datetime feature type to Datetime\n    dataframe[\"Datetime\"] = pd.to_datetime(dataframe[\"Datetime\"].str.replace(\"/\", \"-\"), format = \"%d-%m-%Y %H:%M:%S\")\n    \n    #Remove Date and Time columns\n    dataframe = dataframe.drop(columns = [\"Date\", \"Time\"])\n    \n    return dataframe","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.511491Z","iopub.execute_input":"2024-05-08T13:12:05.511999Z","iopub.status.idle":"2024-05-08T13:12:05.524369Z","shell.execute_reply.started":"2024-05-08T13:12:05.511955Z","shell.execute_reply":"2024-05-08T13:12:05.523482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def date_transform(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n        This fuction creates time-based features\n    \n    \"\"\"\n    \n    dataframe[\"Hour\"] = dataframe.index.hour\n    dataframe[\"Day_ofweek\"] = dataframe.index.dayofweek\n    dataframe[\"Day_ofmonth\"] = dataframe.index.day\n    dataframe[\"Day_ofyear\"] = dataframe.index.dayofyear\n    dataframe[\"Week_ofyear\"] = dataframe.index.isocalendar().week\n    dataframe[\"Month\"] = dataframe.index.month\n    dataframe[\"Quarter\"] = dataframe.index.quarter\n    dataframe[\"Year\"] = dataframe.index.year\n    \n    return dataframe","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.526142Z","iopub.execute_input":"2024-05-08T13:12:05.526557Z","iopub.status.idle":"2024-05-08T13:12:05.542659Z","shell.execute_reply.started":"2024-05-08T13:12:05.526525Z","shell.execute_reply":"2024-05-08T13:12:05.541602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conduct_kruskal_wallist_test(dataframe: pd.DataFrame,\n                                group_feature:str,\n                                target_feature: str = \"Global_active_power\"):\n    \n    \"\"\"\n        This function perform kruskal-wallist-test\n        \n        Parameters:\n            dataframe: pd.DataFrame object to conduct test\n            group_feature: the categorical feature we want to compare\n            target_feature: the feature we want to estimate\n    \"\"\"\n    #Drop NaN values to calculate Kruskal_Wallis results\n    dataframe = dataframe.dropna().copy()\n    #Conduct Kruskal_Wallis Test\n    kruskal_result = kruskal(*[dataframe[target_feature][dataframe[group_feature] == feature] for feature in dataframe[group_feature].unique()])\n    \n    #Display Kruskal-Wallis results\n    print(\"Kruskal-Wallis p-value: \", kruskal_result.pvalue)\n    \n    if kruskal_result.pvalue < 0.05:\n        print(\"At least one group has a significantly different median value\")\n    else:\n        print(\"The medians of the groups do not differ significantly from each other\")\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.54762Z","iopub.execute_input":"2024-05-08T13:12:05.54807Z","iopub.status.idle":"2024-05-08T13:12:05.557704Z","shell.execute_reply.started":"2024-05-08T13:12:05.548033Z","shell.execute_reply":"2024-05-08T13:12:05.556356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_nemenyi_posthoc_test(dataframe:pd.DataFrame,\n                             group_feature:str,\n                             target_feature:str = \"Global_active_power\",\n                             is_mask: bool = True):\n    \n    \"\"\"\n    \n        This function perform Nemenyi Post Hoc Test and plot results\n        \n        Parameters:\n            dataframe: pd.DataFrame object to conduct test\n            group_feature: the categorical feature we want to compare\n            target_feature: the feature we want to estimate\n            is_mask: created to plot the heatmapp according to whether we want a mask in heatmapp or not\n    \"\"\"\n    \n    #Drop NaN values to conduct Nemenyi post hoc test\n    dataframe = dataframe.dropna().copy()\n    #Conduct Nemenyi post hoc test\n    nemenyi_result = posthoc_nemenyi(dataframe,\n                                    val_col = target_feature,\n                                    group_col = group_feature)\n    \n    #Adjust p-values for multiple comparisons\n    p_values = nemenyi_result.values.flatten()\n    adjusted_p_values = multipletests(p_values,\n                                     method = \"bonferroni\")[1].reshape(nemenyi_result.shape)\n    \n    #Display graph for Nemenyi post hoc results\n    plt.figure(figsize = (10, 6))\n    plt.title(\"Significant Differences between Groups (Nemenyi Test)\")\n    \n    if is_mask:\n        #Set the significance level (e.g., 0.05)\n        alpha = 0.05\n        #Create a mask for significant differences\n        mask = adjusted_p_values < alpha\n        \n        sns.heatmap(nemenyi_result,\n                   annot = True,\n                   cmap = \"Spectral\",\n                   fmt = \".2f\",\n                   mask = ~mask)\n        plt.show()\n    \n    else:\n        sns.heatmap(nemenyi_result,\n                   annot = True,\n                   cmap = \"Spectral\",\n                   fmt = \".2f\",\n                   mask = ~mask)\n        plt.show()\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.559928Z","iopub.execute_input":"2024-05-08T13:12:05.560635Z","iopub.status.idle":"2024-05-08T13:12:05.57637Z","shell.execute_reply.started":"2024-05-08T13:12:05.560592Z","shell.execute_reply":"2024-05-08T13:12:05.575134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_dist_pdf_cdf(dataframe: pd.DataFrame, \n                      col: str):\n    \"\"\"\n        This function finds best distribution for feature we want and plot PDF and CDF\n    \n    \"\"\"\n    \n    \n    #Create figure for graph\n    fig, ax = plt.subplots(1, 3, figsize = (30, 10))\n    #Create distribution with 100 boosttraping in popular distributions\n    dfit = distfit(distr = \"popular\")\n    \n    #Fit and transform to feature\n    results = dfit.fit_transform(dataframe.loc[~dataframe[col].isnull(), col].values)\n    #Create graph to find best distribution\n    dfit.plot_summary(n_top = 10, ax=ax[0])\n    # PDF for only the best fit\n    dfit.plot(chart='PDF', n_top=1, ax=ax[1])\n    # CDF for the top 10 fits\n    dfit.plot(chart='CDF', n_top=10, ax=ax[2])\n    \n    #ax[0].set_title(\"Finding Best Distribution with Using Kolmogorov-Smirnov Test and Bootstrapping Technique\")\n    #ax[1].set_title(\"PDF Graph for Best Distribution\")\n    #ax[2].set_title(\"CDF Graph for 10 Best Fit Distributions\")\n    #Show graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.58101Z","iopub.execute_input":"2024-05-08T13:12:05.581748Z","iopub.status.idle":"2024-05-08T13:12:05.593027Z","shell.execute_reply.started":"2024-05-08T13:12:05.581701Z","shell.execute_reply":"2024-05-08T13:12:05.591842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_boxplot(dataframe: pd.DataFrame,\n                x_axis: str,\n                y_axis: str = \"Global_active_power\"):\n\n    # Parameters\n    # dataframe: Dataframe which will draw\n    # x_axis : X axis column for boxplot graph\n    # y_axis : Y axis column for boxplot graph\n    \n    \"\"\"\n        This fucntion created to plot boxplot for comparison of categorical attributes in terms of Global_active_power\n    \n    \"\"\"\n    \n    #Create figure for graph\n    plt.figure(figsize = (30, 6))\n    \n    #Plot boxplot\n    sns.boxplot(data = dataframe,\n               x = x_axis,\n               y = y_axis)\n    \n   # Set title for graph\n    plt.title(f\"{y_axis.capitalize()} by {x_axis}\")\n    \n    #Display graph\n    plt.show()\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.59462Z","iopub.execute_input":"2024-05-08T13:12:05.595588Z","iopub.status.idle":"2024-05-08T13:12:05.6118Z","shell.execute_reply.started":"2024-05-08T13:12:05.595551Z","shell.execute_reply":"2024-05-08T13:12:05.610383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_moving_average(dataframe: pd.DataFrame,\n                        window = int):\n\n    #Parameters\n    #dataframe: Dataframe object which will be use\n    #window: window for rolling\n    \n    \"\"\"\n        This function specify moving averages of Global_active_power and plot them with True values for last 120 values\n    \n    \"\"\"\n    \n    #Create moving average for Global_active_power\n    moving_average = dataframe[\"Global_active_power\"].shift(1).rolling(window).mean()\n    actual = dataframe[\"Global_active_power\"][-(window+120):]\n    ma = dataframe[\"Global_active_power\"][-(window+120):]\n    \n    #Create figure for graph\n    plt.figure(figsize = (15, 6))\n    \n    #Plot graph for actual and moving average values\n    sns.lineplot(actual, label = \"Actual\", color = \"green\")\n    sns.lineplot(ma, label = f\"MA-{window}\", linestyle = \"--\", linewidth = 2, color = \"orange\")\n    \n    #Set title for graph\n    plt.title(f\"Comparison of Moving Averages and Actual Global_active_power values Last 120 Values\",\n             fontsize = 15,\n             weight = \"bold\")\n    #Display graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.613521Z","iopub.execute_input":"2024-05-08T13:12:05.614031Z","iopub.status.idle":"2024-05-08T13:12:05.626224Z","shell.execute_reply.started":"2024-05-08T13:12:05.613994Z","shell.execute_reply":"2024-05-08T13:12:05.625135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def solar_features(latitude: float,\n                   longitude: float,\n                   tz: str,\n                   city: str,\n                   start: str,\n                   end: str):\n    \n    \"\"\"\n        Source: https://github.com/pvlib/pvlib-python\n\n        Features indicating the angle of incidence of the sun's rays to the relevant location.\n\n        We can produce these features as lead and lag features for the period we want.\n        It will not create any leakage element. It was used to reflect the seasonality effect.\n        \n        This dataset contains gni, dni and dhi of Scheax city \n\n    \"\"\"\n    \n    \n    tus = Location(latitude, longitude, tz, 102, city)\n    times = pd.date_range(start, end, freq='H', tz=tus.tz, inclusive = \"left\")\n    cs = tus.get_clearsky(times)  # ineichen with climatology table by default\n    cs=cs.reset_index().rename(columns={'index':'Tarih'})\n    cs['Tarih'] = pd.to_datetime(cs['Tarih'], format = \"%d/%m/%Y %H/%M\")\n    cs['Tarih']=cs['Tarih'].dt.tz_localize(None)\n    cs = cs.iloc[:-2]\n    \n    return cs\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.628558Z","iopub.execute_input":"2024-05-08T13:12:05.629913Z","iopub.status.idle":"2024-05-08T13:12:05.645739Z","shell.execute_reply.started":"2024-05-08T13:12:05.629829Z","shell.execute_reply":"2024-05-08T13:12:05.644461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def advanced_solar_features(latitude: float,\n                           longitude: float,\n                           tz: str,\n                           city: str,\n                           start: str,\n                           end: str\n                           ):\n\n    \"\"\"\n        Source: https://github.com/pvlib/pvlib-python\n\n        Other detailed features indicating the angle of incidence of the sun's rays on the respective location.\n    \n    \n    \"\"\"\n    \n    times = pd.date_range(start, end, freq='H',tz=tz, inclusive = \"left\")\n    #Get solar position in hourly basis for Scheax city\n    solpos = solarposition.get_solarposition(times, latitude, longitude)\n    \n    #Get angle of solar position for Scheax city \n    truetracking_angles = tracking.singleaxis(\n        apparent_zenith=solpos['apparent_zenith'],\n        apparent_azimuth=solpos['azimuth'],\n        axis_tilt=0,\n        axis_azimuth=180,\n        max_angle=90,\n        backtrack=False,  # for true-tracking\n        gcr=0.5)  # irrelevant for true-tracking\n    truetracking_position = truetracking_angles['tracker_theta'].fillna(0)\n    \n    #Some adjustments for solar positions\n    solpos=solpos.reset_index().rename(columns={'index':'Tarih'})\n    solpos['Tarih'] = pd.to_datetime(solpos['Tarih'], format = \"%d/%m/%Y %H/%M\")\n    solpos['Tarih']=solpos['Tarih'].dt.tz_localize(None)\n    solpos=solpos.drop(['zenith','elevation'],axis=1)\n    solpos.drop('apparent_elevation',axis=1,inplace=True)\n    \n    #Some adjustments for angle of solar positions\n    truetracking_position = truetracking_position.reset_index().rename(columns={'index':'Tarih','tracker_theta':'sun_position'})\n    truetracking_position['Tarih'] = pd.to_datetime(truetracking_position['Tarih'], format = \"%d/%m/%Y %H/%M\")\n    truetracking_position['Tarih'] = truetracking_position['Tarih'].dt.tz_localize(None)\n    truetracking_position['Tarih'] = pd.to_datetime(truetracking_position['Tarih'])\n  \n    #Get turbidity of sky\n    turbidity = pvlib.clearsky.lookup_linke_turbidity(times, latitude, longitude, interp_turbidity=True)\n    turbidity=turbidity.reset_index().rename(columns={'index':'Tarih',0:'turbidity'})\n    turbidity['Tarih'] = pd.to_datetime(turbidity['Tarih'], format = \"%d/%m/%Y %H/%M\")\n    turbidity['Tarih']=turbidity['Tarih'].dt.tz_localize(None)\n    \n    \n    return solpos, truetracking_position, turbidity","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.647598Z","iopub.execute_input":"2024-05-08T13:12:05.648747Z","iopub.status.idle":"2024-05-08T13:12:05.666246Z","shell.execute_reply.started":"2024-05-08T13:12:05.648701Z","shell.execute_reply":"2024-05-08T13:12:05.665314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def meteostat_weather_data(latitude:float,\n                           longitude:float,\n                           start:\"str\",\n                           end:\"str\"\n                          ):\n    \n    \"\"\"\n        This function create dataset which contain features like Temperature, Windspeed, Wind direction.\n    \n    \"\"\"\n\n    location = Point(latitude, longitude)\n    weather = Hourly('72219', pd.to_datetime(start), pd.to_datetime(end))\n    weather = weather.fetch()\n    weather = weather.reset_index().rename(columns = {'time':'Tarih'})\n    weather = weather.drop(['snow','wpgt','tsun'],axis=1)\n    weather['Tarih'] = pd.to_datetime(weather['Tarih'])\n    weather = weather.drop(\"coco\", axis = 1)\n    \n    \n    return weather","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.668034Z","iopub.execute_input":"2024-05-08T13:12:05.668743Z","iopub.status.idle":"2024-05-08T13:12:05.684598Z","shell.execute_reply.started":"2024-05-08T13:12:05.668701Z","shell.execute_reply":"2024-05-08T13:12:05.68337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge_dataframes(list_df:list):\n    \"\"\"\n        This function was created to merge train and test set with cs, solpos, weather, turbidity, truetracking_position datasets\n    \n    \"\"\"\n    dfs = []\n    for dataframe in list_df:\n        for other_df in [cs, solpos, weather, turbidity, truetracking_position]:\n            dataframe = dataframe.reset_index()\n            dataframe = pd.merge(dataframe, other_df, left_on = \"Datetime\", right_on = \"Tarih\", how = \"left\")\n            dataframe = dataframe.fillna(method = \"ffill\")\n            dataframe = dataframe.drop(\"Tarih\", axis = 1)\n            dataframe = dataframe.set_index(\"Datetime\")\n            \n        dfs.append(dataframe)\n    return (dfs[0], dfs[1])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.68619Z","iopub.execute_input":"2024-05-08T13:12:05.686537Z","iopub.status.idle":"2024-05-08T13:12:05.70203Z","shell.execute_reply.started":"2024-05-08T13:12:05.686509Z","shell.execute_reply":"2024-05-08T13:12:05.700938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_pie(\n            dataframe: pd.DataFrame,\n            columns_pie: list,\n            title: str = \"Upper\"\n):\n    # Parameters:\n    # dataframe: Dataframe which will draw\n    # columns_pie: Columns which draw in pie graph\n    \n    \"\"\"\n        This function plots pie graph for features\n    \"\"\"\n    \n    #Create figure and axes for graph\n    fig, ax = plt.subplots(nrows = 1, ncols = len(columns_pie), figsize = (18, 10))\n    \n    for i ,col in enumerate(columns_pie):\n        #Get value_counts of feature\n        value_columns_target = dataframe[col].value_counts()\n        #Plot pie graph for feature\n        ax[i].pie(value_columns_target.values, labels = value_columns_target.index, startangle = 140) #autopct='%1.1f%%'\n        #Set title for axis\n        ax[i].set_title(f\"{col.capitalize()} Pie Chart\")\n    \n    #Create a str for features in columns_pie\n    str_list = \", \".join(columns_pie)\n    #Set title for pie\n    fig.suptitle(f\" Examination of {title} Outlier Values By {str_list}\", fontsize = 16, weight = \"bold\", y = 0.80)\n    #Display graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.70375Z","iopub.execute_input":"2024-05-08T13:12:05.704369Z","iopub.status.idle":"2024-05-08T13:12:05.71477Z","shell.execute_reply.started":"2024-05-08T13:12:05.704335Z","shell.execute_reply":"2024-05-08T13:12:05.713698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_columns(\n                dataframe: pd.DataFrame,\n                list_col: list\n):\n    \n    \"\"\"\n        In August 2008, we checked the values of the attributes. \n        Our goal is to gain insight into whether the continuous drop of the global_active_power attribute in this month is \n        due to measurement error or whether the values are normal.\n    \n    \"\"\"\n    #Creater figure and axes\n    fig, ax = plt.subplots(nrows = len(list_col), ncols  = 1, figsize = (20, 5*len(list_col)))\n    \n    for i, col in enumerate(list_col):\n        #Plot feature values in train data set\n        df_train[col].plot(label = col, color = \"Red\", ax = ax[i])\n        #Plot vertical line in 2008-08-1\n        ax[i].axvline(\"2008-08-01 00:00:00\", linestyle = \"--\", linewidth = 3)\n        #Plot vertical line in 2008-09-1\n        ax[i].axvline(\"2008-09-01 00:00:00\", linestyle = \"--\", linewidth = 3)\n        \n        ax[i].legend()\n    \n    #Set title for graph\n    fig.suptitle(\"Check Between 2008 August and September\", weight = \"bold\", fontsize = 15, y = 0.92)\n    #Display graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:30:04.349678Z","iopub.execute_input":"2024-05-08T13:30:04.350101Z","iopub.status.idle":"2024-05-08T13:30:04.360999Z","shell.execute_reply.started":"2024-05-08T13:30:04.350068Z","shell.execute_reply":"2024-05-08T13:30:04.359267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPORT LIBRARY","metadata":{}},{"cell_type":"code","source":"%%time\ndf = pd.read_csv(config.dir_dataset, sep = \";\")\ndf.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:05.733649Z","iopub.execute_input":"2024-05-08T13:12:05.734344Z","iopub.status.idle":"2024-05-08T13:12:09.795106Z","shell.execute_reply.started":"2024-05-08T13:12:05.734311Z","shell.execute_reply":"2024-05-08T13:12:09.794022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:09.796658Z","iopub.execute_input":"2024-05-08T13:12:09.797036Z","iopub.status.idle":"2024-05-08T13:12:09.810379Z","shell.execute_reply.started":"2024-05-08T13:12:09.797005Z","shell.execute_reply":"2024-05-08T13:12:09.809391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:09.811888Z","iopub.execute_input":"2024-05-08T13:12:09.812493Z","iopub.status.idle":"2024-05-08T13:12:11.576397Z","shell.execute_reply.started":"2024-05-08T13:12:09.812457Z","shell.execute_reply":"2024-05-08T13:12:11.575144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only the **Sub_metering_3** column has nan values.\n\n-----------------------------------------------------\n\nYalnızca **Sub_metering_3** sütunu nan değerlere sahiptir.","metadata":{}},{"cell_type":"code","source":"df[df[\"Sub_metering_3\"].isnull()]","metadata":{"execution":{"iopub.status.busy":"2024-05-08T13:12:11.577974Z","iopub.execute_input":"2024-05-08T13:12:11.578784Z","iopub.status.idle":"2024-05-08T13:12:11.608147Z","shell.execute_reply.started":"2024-05-08T13:12:11.578736Z","shell.execute_reply":"2024-05-08T13:12:11.606731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sub_metering_3 sütununun NaN olduğu satırlarda Date ve Time hariç diğer sütunlarda \"?\" değerini almıştır.\n\n----------------------------------------------------------------------------------------------------------\n\nIn rows where the Sub_metering_3 column is NaN, the other columns except Date and Time have the value “?”.","metadata":{}},{"cell_type":"code","source":"%%time\ndf = preprocessing(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T13:12:11.609957Z","iopub.execute_input":"2024-05-08T13:12:11.610337Z","iopub.status.idle":"2024-05-08T13:12:34.641628Z","shell.execute_reply.started":"2024-05-08T13:12:11.610303Z","shell.execute_reply":"2024-05-08T13:12:34.640366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set index and resample in terms of hours\ndf = df.set_index(\"Datetime\")\nprint(f\"Old Dataframe Shape: {df.shape}\")\n#Convert data set to hourly time zone\ndf = df.resample(\"H\").mean().copy()\nprint(f\"Resampled DataFrame Shape: {df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T13:12:34.643029Z","iopub.execute_input":"2024-05-08T13:12:34.643375Z","iopub.status.idle":"2024-05-08T13:12:34.884854Z","shell.execute_reply.started":"2024-05-08T13:12:34.643345Z","shell.execute_reply":"2024-05-08T13:12:34.883943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creation and Comparison of Test and Train Datasets","metadata":{}},{"cell_type":"code","source":"# Create Test and Train Datasets\ndf_train = df[df.index <= \"2010-06-01\"].copy()\ndf_test = df[df.index > \"2010-06-01\"].copy()\n\nprint(f\"Train dataset shape: {df_train.shape}\")\nprint(f\"Test dataset shape: {df_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T13:12:34.88587Z","iopub.execute_input":"2024-05-08T13:12:34.886193Z","iopub.status.idle":"2024-05-08T13:12:34.900753Z","shell.execute_reply.started":"2024-05-08T13:12:34.886166Z","shell.execute_reply":"2024-05-08T13:12:34.89929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Şimdi train ve test veri setlerindeki Global_active_power değerlerine bakalım.\n\n------------------------------------------------------------------------------\n\nNow let's look at Global_active_power values in train and test datasets.","metadata":{}},{"cell_type":"code","source":"#Show Global Active Power from Test and Train Datasets\nplt.figure(figsize = (20, 6))\ndf_train[\"Global_active_power\"].plot(label = \"Training Set\", color = \"Red\")\ndf_test[\"Global_active_power\"].plot(label  = \"Test Set\", color = \"Orange\")\nplt.axvline(\"2010-06-01 00:00:00\", linestyle = \"--\", linewidth = 3)\nplt.text(\"2010-06-02 00:00:00\", 6, \"Split\", fontsize = 20, fontweight = \"bold\")\nplt.title(\"Data Splitting\", weight = \"bold\", fontsize = 15)\nplt.legend()\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:34.907474Z","iopub.execute_input":"2024-05-08T13:12:34.907888Z","iopub.status.idle":"2024-05-08T13:12:38.494423Z","shell.execute_reply.started":"2024-05-08T13:12:34.907841Z","shell.execute_reply":"2024-05-08T13:12:38.493226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2008 yılının Ağustos ayında değerler dürekli biçimde oldukça aşağıda gelmiştir.\n\nTest ve trains setindeki özelliklerin birbiri ile benzer dağılımlara sahip olması önemlidir. Çünkü train veri seti ile öğrenirken modelin doğruluğunu test veri seti ile yapacağız. \n\n---------------------------------------------------------------------------------------------\n\nIn August 2008 the values were consistently quite low.\n\nIt is important that the features in the test and trains set have similar distributions. Because while we learn the model with the train data set, we will verify the accuracy of the model with the test data set. \n\n","metadata":{}},{"cell_type":"code","source":"# Compared train to test datasets\ni = 1\ncols = [\n    \"Global_active_power\",\n    \"Global_reactive_power\",\n    \"Voltage\",\n    \"Global_intensity\",\n    \"Sub_metering_1\",\n    \"Sub_metering_2\",\n    \"Sub_metering_3\"\n]\n#Create figure for graphs\nplt.figure(figsize = (15, 30))\n\nfor col in cols:\n    plt.subplot(len(cols), 1, i)\n    sns.kdeplot(df_train[col], label  = \"Training Set\", color = \"blue\")\n    sns.kdeplot(df_test[col], label  = \"Test Set\", color = \"orange\")\n    plt.title(f\"{col} Training vs Test Set\")\n    plt.gca().axes.get_xaxis().set_visible(False)\n    i += 1\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:12:38.495681Z","iopub.execute_input":"2024-05-08T13:12:38.496063Z","iopub.status.idle":"2024-05-08T13:12:42.289624Z","shell.execute_reply.started":"2024-05-08T13:12:38.496031Z","shell.execute_reply":"2024-05-08T13:12:42.288258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test ve Train veri setindeki özellik olasılık dağılımları birbirine benzerdir. Bu istenen bir özelliktir.\n\n----------------------------------------------------------------------------------------------------------\n\nThe feature probability distributions in the Test and Train dataset are similar. This is a desirable property.","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## Check Between 2008 August and September","metadata":{}},{"cell_type":"code","source":"list_col = [\n            \"Global_reactive_power\",\n            \"Voltage\",\n            \"Global_intensity\",\n            \"Sub_metering_1\",\n            \"Sub_metering_2\",\n            \"Sub_metering_3\"\n]\n\nplot_columns(df_train, list_col)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:30:10.794578Z","iopub.execute_input":"2024-05-08T13:30:10.79504Z","iopub.status.idle":"2024-05-08T13:30:28.675506Z","shell.execute_reply.started":"2024-05-08T13:30:10.795004Z","shell.execute_reply":"2024-05-08T13:30:28.674541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Görüyoruzki 2008 yılının Ağustos Global_reactive_power, Sub_meterings_1, Sub_meterings_2 ve Sub_meterings_3 özelliklerinde de düşüş var. Bu ayda yaşayan aile bir yere tatile gitmiş olabilir.\n\n---------------------------------------------------------------------------------------------------\n\nWe see that in August 2008 there is a decrease in Global_reactive_power, Sub_meterings_1, Sub_meterings_2 and Sub_meterings_3. The family living in this month may have gone on vacation somewhere.","metadata":{}},{"cell_type":"markdown","source":"## Correlation","metadata":{}},{"cell_type":"code","source":"#Create figure for graph\nplt.figure()\n#Determine correlations of features\ncorrelations = df_train.corr().abs()\n#Determine mask for heatmapp\nmask = np.triu(np.ones_like(correlations, dtype = \"bool\"))\n#Plot heatmapp\nsns.heatmap(correlations, annot = True, fmt = \".2f\", cmap = \"Spectral\", mask = mask)\n#Display graph\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:22.383463Z","iopub.execute_input":"2024-05-08T11:13:22.384504Z","iopub.status.idle":"2024-05-08T11:13:22.83848Z","shell.execute_reply.started":"2024-05-08T11:13:22.384469Z","shell.execute_reply":"2024-05-08T11:13:22.837259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Global_active_power ile Global_intensity özellikleri birbiri ile oldukça yüksek korelasyona sahiptir.\n- Target değeri ile Global_active_power ve Sub_metering_3 özelliği diğerlerine nazaran yüksek korelasyona sahiptir.\n- Target değeri ile Global_reactive_power ve Sub_metering_2 özelliği düşük korelasyon değerine sahiptir.\n\n-------------------------------------------------------------------------------------------------------\n\n- Global_active_power and Global_intensity are highly correlated with each other.\n- Target has a high correlation with Global_active_power and Sub_metering_3.\n- Target has a low correlation with Global_reactive_power and Sub_metering_2.","metadata":{}},{"cell_type":"markdown","source":"We will remove Global_intensity feature because of high correlation","metadata":{}},{"cell_type":"code","source":"#Remove Global_intensity feature\ndf_train = df_train.drop(\"Global_intensity\", axis = 1)\ndf_test = df_test.drop(\"Global_intensity\", axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:22.839815Z","iopub.execute_input":"2024-05-08T11:13:22.840201Z","iopub.status.idle":"2024-05-08T11:13:22.846991Z","shell.execute_reply.started":"2024-05-08T11:13:22.840171Z","shell.execute_reply":"2024-05-08T11:13:22.846092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Value_counts","metadata":{}},{"cell_type":"code","source":"cols = [\n    \"Global_active_power\",\n    \"Global_reactive_power\",\n    \"Voltage\",\n    \"Sub_metering_1\",\n    \"Sub_metering_2\",\n    \"Sub_metering_3\"\n]\nfor col in cols:\n    print(f\"*\" * 50)\n    print(f\"{df_train[col].value_counts()}\")\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:22.848464Z","iopub.execute_input":"2024-05-08T11:13:22.849077Z","iopub.status.idle":"2024-05-08T11:13:22.885606Z","shell.execute_reply.started":"2024-05-08T11:13:22.849033Z","shell.execute_reply":"2024-05-08T11:13:22.884438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Sub_metering_1, Sub_metering_2 ve Sub_metering_3 özelliğinde oldukça çok sayıda 0 değeri bulunmaktadır.\n\n-------------------------------------------------------------------------------------------------\n\n- Sub_metering_1, Sub_metering_2 and Sub_metering_3 have a large number of 0 values.","metadata":{}},{"cell_type":"code","source":"# Creating new features based on whether the sub_metering_? property is 0 or not\ndf_train.loc[df_train[\"Sub_metering_1\"] == 0, \"is_sub_meter_1\"] = \"Equal 0\"\ndf_train.loc[df_train[\"Sub_metering_1\"] != 0, \"is_sub_meter_1\"] = \"Not Equal 0\"\n\ndf_train.loc[df_train[\"Sub_metering_2\"] == 0, \"is_sub_meter_2\"] = \"Equal 0\"\ndf_train.loc[df_train[\"Sub_metering_2\"] != 0, \"is_sub_meter_2\"] = \"Not Equal 0\"\n\ndf_train.loc[df_train[\"Sub_metering_3\"] == 0, \"is_sub_meter_3\"] = \"Equal 0\"\ndf_train.loc[df_train[\"Sub_metering_3\"] != 0, \"is_sub_meter_3\"] = \"Not Equal 0\"\n\ncols = [\n    \"is_sub_meter_1\",\n    \"is_sub_meter_2\",\n    \"is_sub_meter_3\"\n]\n\ncompared_cols = [\n    \"Sub_metering_1\",\n    \"Sub_metering_2\",\n    \"Sub_metering_3\"\n]\n\n#Create figure for graph\nplt.figure(figsize = (15,18))\nfor i, col in enumerate(cols):\n    #Plot kdeplot Comparison of the Global_Active_power feature according to whether the is_sub_meter_? feature is 0 or not\n    plt.subplot(len(cols), 1, i+1)\n    sns.kdeplot(df_train, x = \"Global_active_power\", hue = cols[i])\n    plt.title(f\"Comparison of the Global_Active_power feature according to whether the {compared_cols[i]} feature is 0 or not\", fontsize = 15, fontweight = \"bold\")\n    plt.gca().axes.get_xaxis().set_visible(False)\n    \n    #Drop is_sub_meter_? features\n    df_train = df_train.drop(col, axis = 1)\n\n#Display graph\nplt.show()\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:22.887304Z","iopub.execute_input":"2024-05-08T11:13:22.887628Z","iopub.status.idle":"2024-05-08T11:13:24.736821Z","shell.execute_reply.started":"2024-05-08T11:13:22.8876Z","shell.execute_reply":"2024-05-08T11:13:24.735605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Sub_meter_1 özelliği 0 olan satırlar ile 0 olmayan satırların Global_active_power dağılımları arasında **oldukça fazla** fark bulunmaktadır.\n- Sub_meter_2 özelliği 0 olan satırlar ile 0 olmayan satırların Global_active_power dağılımları  **birbirine benzemektedir**.\n- Sub_meter_3 özelliği 0 olan satırlar ile 0 olmayan satırların Global_active_power dağılımları arasında **birbirine yakınsamıştır**.\n\n----------------------------------------------------------------------------------------------------\n\n- There is a **very large** difference between the Global_active_power distributions of rows with sub_meter_1 property 0 and rows without 0.\n- The Global_active_power distributions of rows with sub_meter_2 property 0 and rows without 0 are **similar**.\n- The Global_active_power distributions of rows with sub_meter_3 feature 0 and rows without 0 are **converged**.","metadata":{}},{"cell_type":"markdown","source":"## Find Best Distributions for Features","metadata":{}},{"cell_type":"markdown","source":"The distfit library can determine the best fit across 89 theoretical distributions which are utilized from the scipy library. To score the fit, there are four goodness-of-fit statistical tests; Residual Sum of Squares (RSS or SSE), Wasserstein, Kolmogorov-Smirnov (KS), and Energy. For each fitted theoretical distribution, the loc, scale, and arg parameters are returned, such as mean and standard deviation for normal distribution.\n\nAnd also best practice is to use both statistics and a visual curation to decide what the best distribution fit is. Using the PDF/CDF and QQ plots can be some of the best tools to guide those decisions. These plots will help to visually guide whether a distribution is a good fit. We can see in graphs the PDF with the confidence intervals and the CDF plot. The confidence intervals are automatically set to 95% CII but can be changed using the alpha parameter during initialization. When using the plot functionality, it automatically shows the histogram in bars and with a line, PDF/CDF, and confidence intervals. \n\n\n[Source](http://https://towardsdatascience.com/how-to-find-the-best-theoretical-distribution-for-your-data-a26e5673b4bd)","metadata":{}},{"cell_type":"code","source":"# Find best distribution for Global_active_power\nplot_dist_pdf_cdf(df_train, \"Global_active_power\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:24.738716Z","iopub.execute_input":"2024-05-08T11:13:24.739625Z","iopub.status.idle":"2024-05-08T11:13:29.260253Z","shell.execute_reply.started":"2024-05-08T11:13:24.73958Z","shell.execute_reply":"2024-05-08T11:13:29.259108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Global_active_power özelliği en çok log-normal dağılıma benzemektedir. Bu bilgiyi daha sonradan kullanacağım.\n\n------------------------------------------------------------------------------------\n\nThe global_active_power property is most similar to the log-normal distribution. I will use this information later.","metadata":{}},{"cell_type":"code","source":"# Find best distribution for Global_reactive_power\n#plot_dist_pdf_cdf(df_train, \"Global_reactive_power\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:29.261783Z","iopub.execute_input":"2024-05-08T11:13:29.262202Z","iopub.status.idle":"2024-05-08T11:13:29.267069Z","shell.execute_reply.started":"2024-05-08T11:13:29.262167Z","shell.execute_reply":"2024-05-08T11:13:29.265901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find best distribution for Voltage\n#plot_dist_pdf_cdf(df_train, \"Voltage\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:29.268457Z","iopub.execute_input":"2024-05-08T11:13:29.268932Z","iopub.status.idle":"2024-05-08T11:13:29.280242Z","shell.execute_reply.started":"2024-05-08T11:13:29.268876Z","shell.execute_reply":"2024-05-08T11:13:29.279118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find best distribution for Sub_metering_1\n#plot_dist_pdf_cdf(df_train, \"Sub_metering_1\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:29.28189Z","iopub.execute_input":"2024-05-08T11:13:29.282324Z","iopub.status.idle":"2024-05-08T11:13:29.291477Z","shell.execute_reply.started":"2024-05-08T11:13:29.282286Z","shell.execute_reply":"2024-05-08T11:13:29.290207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find best distribution for Sub_metering_2\n#plot_dist_pdf_cdf(df_train, \"Sub_metering_2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:29.292838Z","iopub.execute_input":"2024-05-08T11:13:29.293195Z","iopub.status.idle":"2024-05-08T11:13:29.303796Z","shell.execute_reply.started":"2024-05-08T11:13:29.293166Z","shell.execute_reply":"2024-05-08T11:13:29.302717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find best distribution for Sub_metering_3\n#plot_dist_pdf_cdf(df_train, \"Sub_metering_3\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:29.30517Z","iopub.execute_input":"2024-05-08T11:13:29.305522Z","iopub.status.idle":"2024-05-08T11:13:29.316719Z","shell.execute_reply.started":"2024-05-08T11:13:29.305493Z","shell.execute_reply":"2024-05-08T11:13:29.315704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add time-based features","metadata":{}},{"cell_type":"markdown","source":"Veri setimize zaman tabanlı özellikler ekleyeceğiz. Bu özellikler; saat, haftanın kaçıncı günü (day of week), ayın kaçıncı günü (day of month), yılın kaçıncı günü (day of year), yılın kaçıncı haftası (week of year), ay, dönem ve yıl olacaktır. Bu özelliklerden haftanın kaçıncı günü, ay ve yıl bilgilerinin kategorik verileri arasında fark olup olmadığını anlamak için istatistiki yöntem uygulayacağım. Diğerleri için de boxplot yöntemi kullanarak farkları anlamaya çalışacağım.\n\n------------------------------------------------------------------------------------------------------\n\n\nWe will add time-based features to our dataset. These features will be time, day of week, day of month, day of month, day of year, week of year, month, period and year. I will apply a statistical method to see if there is a difference between the categorical data for the day of the week, month and year. For the others, I will try to understand the differences using the boxplot method.","metadata":{}},{"cell_type":"code","source":"for dataframe in [df_train, df_test]:\n    date_transform(dataframe)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:29.318126Z","iopub.execute_input":"2024-05-08T11:13:29.318517Z","iopub.status.idle":"2024-05-08T11:13:29.348096Z","shell.execute_reply.started":"2024-05-08T11:13:29.318486Z","shell.execute_reply":"2024-05-08T11:13:29.346917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bizim sistemimizdeki zaman bazlı özelliklerin hepsi kategoriktir. Bizde kategoriler arasında Global_active_power özelliği için bir fark olup olmadığını anlamak istiyoruz. Bunun için birkaç istatistiki yöntem bulunmaktadır. Biliyoruz ki Global_active_power özelliği normal dağılıma sahip değildir. Dolayısıyla normal dağılımı varsayan testleri eleyeceğiz. Biz Kruskal-Wallis test yöntemini uygulayacağız.\n\nBu yöntem;\n\nParametrik olmayan bir bir yöntemdir ve farklı grupların medyanları arasında istatistiksel olarak anlamlı farklılıklar olup olmadığını belirlemek için kullanılır.\n                                                    \n                                Null Hypothesis (H0): Grupların medyanları birbirine eşittir.\n\n                                Alternative Hypothesis (H1): En azından bir grup farklı medyan değerine sahiptir.\n\nP-değerinin yorumlanması:\n\np-değeri < 0,05: Sıfır hipotezini reddedersiniz. Bu, en az bir grubun farklı bir medyana sahip olduğu sonucuna varmak için kanıt olduğunu gösterir.\n\np-değeri >= 0,05: Sıfır hipotezini reddedemezsiniz. Bu, gruplar arasında ortanca farklılıkları olduğu sonucuna varmak için yeterli kanıt olmadığını gösterir.\n\nKruskal-Wallis testi, iki veya daha fazla grubun medyanlarını karşılaştırmak için kullanılan istatistiksel testtir. Gruplar arasında anlamlı farklılıklar olup olmadığını belirlemek için kullanılır. Testin anlamlı olması, grupların medyanları arasında bir fark olduğunu gösterir, ancak hangi grupların birbirinden önemli ölçüde farklı olduğunu söylemez.\n\nİşte bu noktada Nemenyi testi devreye girer. Hangi grup çiftlerinin birbirinden önemli ölçüde farklı olduğunu belirlemek için kullanılan bir çoklu karşılaştırma testidir. \"Kritik fark grafiği\" adı verilen ve her bir grup çiftinin ortalamaları arasındaki farkı bir \"kritik fark\" çizgisiyle birlikte gösteren bir grafik oluşturur. Bir grup çiftinin ortalamaları arasındaki fark kritik farktan büyükse, grupların önemli ölçüde farklı olduğu kabul edilir.\n\nGenel olarak, Nemenyi testi, ilk Kruskal-Wallis testi yapıldıktan sonra hangi grupların birbirinden önemli ölçüde farklı olduğunu belirlemek için yararlı bir araçtır. İstatistiksel analizinizin sonuçlarını anlamanıza ve verilerinizden anlamlı sonuçlar çıkarmanıza yardımcı olabilir.\n\n-----------------------------------------------------------------------------------------------------------------\n\nAll time-based properties in our system are categorical. We want to see if there is a difference between categories for the Global_active_power property. There are several statistical methods for this. We know that Global_active_power is not normally distributed. Therefore, we will eliminate tests that assume a normal distribution. We will apply the Kruskal-Wallis test method.\n\nThis method\n\nIt is a non-parametric method and is used to determine whether there are statistically significant differences between the medians of different groups.\n                                                    \n                                Null Hypothesis (H0): The medians of the groups are equal.\n\n                                Alternative Hypothesis (H1): At least one group has a different median value.\n\nInterpretation of p-value:\n\np-value < 0.05: You reject the null hypothesis. This indicates that there is evidence to conclude that at least one group has a different median.\n\np-value >= 0.05: You cannot reject the null hypothesis. This indicates that there is not enough evidence to conclude that there are differences in the median between the groups.\n\nThe Kruskal-Wallis test is a statistical test used to compare the medians of two or more groups. It is used to determine whether there are significant differences between groups. A significant test indicates that there is a difference between the medians of the groups, but it does not tell us which groups are significantly different from each other.\n\nThis is where the Nemenyi test comes in. It is a multiple comparison test used to determine which pairs of groups are significantly different from each other. It produces a graph called a “critical difference plot”, which shows the difference between the means of each pair of groups with a “critical difference” line. If the difference between the means of a pair of groups is greater than the critical difference, the groups are considered to be significantly different.\n\nIn general, the Nemenyi test is a useful tool for determining which groups are significantly different from each other after the initial Kruskal-Wallis test has been performed. It can help you understand the results of your statistical analysis and draw meaningful conclusions from your data.","metadata":{}},{"cell_type":"code","source":"# Comparison of Global_active_power in terms of day of week\nconduct_kruskal_wallist_test(dataframe = df_train,\n                            group_feature = \"Day_ofweek\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:29.349703Z","iopub.execute_input":"2024-05-08T11:13:29.350048Z","iopub.status.idle":"2024-05-08T11:13:29.395004Z","shell.execute_reply.started":"2024-05-08T11:13:29.350018Z","shell.execute_reply":"2024-05-08T11:13:29.392952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform Nemenyi Post Hoc Method to understand differences between day of week\nplot_nemenyi_posthoc_test(dataframe = df_train,\n                         group_feature = \"Day_ofweek\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:29.397851Z","iopub.execute_input":"2024-05-08T11:13:29.399476Z","iopub.status.idle":"2024-05-08T11:13:29.898846Z","shell.execute_reply.started":"2024-05-08T11:13:29.399397Z","shell.execute_reply":"2024-05-08T11:13:29.897727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Burada Pazartesi gününün indisi 0'dan başlar ve Pazar gününün indisi 6 ile biter.\n- Sonuçlara göre günler Global_active_power değerlerine göre karşılaştırıldığında;\n    - Pazartesi günü; Cumartesi ve Pazar günü ile anlamlı olarak farklı medyan değerine sahiptir.\n    - Salı günü, hiçbir gün ile anlamlı olarak farklı medyan değerine sahip değildir.\n    - Çarşama günü, hiçbir gün ile anlamlı olarak farklı medyan değerine sahip değildir.\n    - Perşembe günü; Cumartesi ve Pazar günü ile anlamlı olarak farklı medyan değerine sahiptir. \n    - Cuma günü, Pazar günü ile anlamlı olarak farklı medyan değerine sahiptir.\n    - Cumartesi günü; Pazartesi ,Perşembe ve Cuma günleri ile anlamlı olarak farklı medyan değerlerine sahiptir.\n    - Pazar günü; Pazartesi ve Perşembe günü ile anlamlı olarak farklı medyan değerlerine sahiptir.\n    \n    -----------------------------------------------------------------------------------------------------\n    \n- Here, Monday's index starts at 0 and Sunday's index ends with 6.\n- According to the results, when days are compared according to their Global_active_power values;\n    - Monday has a significantly different median value than Saturday and Sunday.\n    - Tuesday does not have a significantly different median value than any other day.\n    - Wednesday does not have a significantly different median value with any day.\n    - Thursday has a significantly different median value from Saturday and Sunday. \n    - Friday has a significantly different median value from Sunday.\n    - Saturday has significantly different median values from Monday, Thursday and Friday.\n    - Sunday has significantly different median values from Monday and Thursday.\n     \n     ","metadata":{}},{"cell_type":"code","source":"# Comparison of Global_active_power in terms of month\nconduct_kruskal_wallist_test(dataframe = df_train,\n                            group_feature = \"Month\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:29.9002Z","iopub.execute_input":"2024-05-08T11:13:29.900539Z","iopub.status.idle":"2024-05-08T11:13:29.928247Z","shell.execute_reply.started":"2024-05-08T11:13:29.90051Z","shell.execute_reply":"2024-05-08T11:13:29.927149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform Nemenyi Post Hoc Method to understand differences between months\nplot_nemenyi_posthoc_test(dataframe = df_train,\n                         group_feature = \"Month\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:29.929623Z","iopub.execute_input":"2024-05-08T11:13:29.929998Z","iopub.status.idle":"2024-05-08T11:13:30.875934Z","shell.execute_reply.started":"2024-05-08T11:13:29.929968Z","shell.execute_reply":"2024-05-08T11:13:30.874656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Aylar indis olarak Ocakta 1 ile başlar ve Aralıkta 12 ile biter.\nSonuçlara göre aylar Global_active_power değerlerine göre karşılaştırıldığında;\n    - Ocak Ayı; Kasım ve Aralık ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Şubat Ayı; Mart, Nisan, Mayıs, Eylül ve Ekim ayları ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Mart Ayı; Şubat, Nisan, Mayıs, Ekim ve Kasım ayları ile anlamlı olarak benzer medyan değerine sahiptir\n    - Nisan Ayı; Şubat, Mart, Mayıs, Eylül ve Ekim ayları ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Mayıs Ayı, Şubat, Mart, Nisan, Eylül ve Ekim ayları ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Haziran Ayı; Temmuz ve Eylül ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Temmuz Ayı; Haziran ve Ağustos ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Ağustos Ayı; Temmuz ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Eylül Ayı; Şubat, Nisan, Mayıs, Haziran ve Ağustos ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Ekim Ayı; Şubat, Mart, Nisan, Mayıs ve Eylül ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Kasım Ayı; Ocak, Mart ve Aralık ayı ile anlamlı olarak benzer medyan değerine sahiptir.\n    - Aralık Ayı; Ocak ve Kasım ile anlamlı olarak benzer medyan değerine sahiptir.\n    \n    --------------------------------------------------------------------------------------------------\n    \n    - Months start with 1 in January and end with 12 in December.\nAccording to the results, when months are compared according to Global_active_power values;\n        - January has a significantly similar median value with November and December.\n        - February has a significantly similar median value with March, April, May, September and October.\n        - March has a significantly similar median value with February, April, May, October and November.\n        - April has a significantly similar median value with February, March, May, September and October.\n        - May has a significantly similar median value with February, March, April, September and October.\n        - June has a significantly similar median value with July and September.\n        - July has a significantly similar median value with June and August.\n        - August has a significantly similar median value with July.\n        - September has a significantly similar median value with February, April, May, June and August.\n        - October has a significantly similar median value with February, March, April, May and September.\n        - November has a significantly similar median value with January, March and December.\n        - December has a significantly similar median value with January and November.\n","metadata":{}},{"cell_type":"code","source":"# Comparison of Global_active_power in terms of year\nconduct_kruskal_wallist_test(dataframe = df_train,\n                            group_feature = \"Year\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:30.877422Z","iopub.execute_input":"2024-05-08T11:13:30.878045Z","iopub.status.idle":"2024-05-08T11:13:30.903598Z","shell.execute_reply.started":"2024-05-08T11:13:30.878013Z","shell.execute_reply":"2024-05-08T11:13:30.902669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform Nemenyi Post Hoc Method to understand differences between years\nplot_nemenyi_posthoc_test(dataframe = df_train,\n                         group_feature = \"Year\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:30.905016Z","iopub.execute_input":"2024-05-08T11:13:30.905331Z","iopub.status.idle":"2024-05-08T11:13:31.319461Z","shell.execute_reply.started":"2024-05-08T11:13:30.905304Z","shell.execute_reply":"2024-05-08T11:13:31.318251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sonuçlara göre yıllar Global_active_power değerlerine göre karşılaştırıldığında;\n\n   - 2006 yılı, diğer bütün yıllar ile anlamlı bir farklılığa sahiptir.\n   - 2007 yılı, 2008 yılı ile anlamlı benzerliğe sahiptir.\n   - 2008 yılı, 2007 yılı ile anlamlı benzerliğe sahiptir.\n   - 2009 yılı, diğer bütün yıllar ile anlamlı bir farklılığa sahiptir.\n   - 2010 yılı, diğer bütün yıllar ile anlamlı bir farklılığa sahiptir.\n   \n   ------------------------------------------------------------------------------------\n   \n   According to the results, when the years are compared according to Global_active_power values;\n    \n   - 2006 has a significant difference with all other years.\n   - 2007 has a significant similarity with 2008.\n   - 2008 has a significant similarity with 2007.\n   - 2009 has a significant difference with all other years.\n   - 2010 has a significant difference with all other years.\n","metadata":{}},{"cell_type":"code","source":"# Plot boxplot to understand relationship between day of year and global_active_power feature\nplot_boxplot(df_train, x_axis = \"Day_ofyear\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:31.320914Z","iopub.execute_input":"2024-05-08T11:13:31.321255Z","iopub.status.idle":"2024-05-08T11:13:37.956644Z","shell.execute_reply.started":"2024-05-08T11:13:31.321225Z","shell.execute_reply":"2024-05-08T11:13:37.955466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Yılların günlerine göre oldukça farklılık gözlenmektedir.\n\n-------------------------------------------------------------------------------\n\n- There is considerable variation according to the days of the year.","metadata":{}},{"cell_type":"code","source":"# Plot boxplot to understand relationship between day of month and global_active_power feature\nplot_boxplot(df_train, x_axis = \"Day_ofmonth\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:37.95804Z","iopub.execute_input":"2024-05-08T11:13:37.958365Z","iopub.status.idle":"2024-05-08T11:13:38.794637Z","shell.execute_reply.started":"2024-05-08T11:13:37.958337Z","shell.execute_reply":"2024-05-08T11:13:38.793506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Ayın 8. günü diğer günlere göre oldukça küçük medyan değerine sahiptir.\n- Ayın 1'i, 2'si, 15', ve 31'i diğerlerine göre büyük medyanlara sahiptir.\n\n-------------------------------------------------------------------------------------------\n\n- The 8th day of the month has a very small median value compared to other days.\n- The 1st, 2nd, 15th, and 31st of the month have larger medians than the others.","metadata":{}},{"cell_type":"code","source":"# Plot boxplot to understand relationship between week of year and global_active_power feature\nplot_boxplot(df_train, x_axis = \"Week_ofyear\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:38.796008Z","iopub.execute_input":"2024-05-08T11:13:38.796342Z","iopub.status.idle":"2024-05-08T11:13:39.981675Z","shell.execute_reply.started":"2024-05-08T11:13:38.796313Z","shell.execute_reply":"2024-05-08T11:13:39.980556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Yılın 29, 30, 34 ve 35. haftaları diğer haftalara göre daha küçük medyan değerine sahiptir.\n- Yılın 3, 4, 7, 12, 13, 46, 47, 48, 50, 51 ve 52. haftaları diğerlerien göre daha büyük medyan değerine sahiptir.\n\n--------------------------------------------------------------------------------------------------------\n\n- The 29th, 30th, 34th and 35th weeks of the year have smaller median values than the other weeks.\n- Weeks 3, 4, 7, 12, 13, 46, 47, 48, 50, 51 and 52 of the year have larger median values than the others.","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:41:47.68966Z","iopub.execute_input":"2024-04-19T18:41:47.690115Z","iopub.status.idle":"2024-04-19T18:41:47.698909Z","shell.execute_reply.started":"2024-04-19T18:41:47.69008Z","shell.execute_reply":"2024-04-19T18:41:47.69729Z"}}},{"cell_type":"code","source":"# Plot boxplot to understand relationship between quarter and global_active_power feature\nplot_boxplot(df_train, x_axis = \"Quarter\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:39.983768Z","iopub.execute_input":"2024-05-08T11:13:39.984168Z","iopub.status.idle":"2024-05-08T11:13:40.385166Z","shell.execute_reply.started":"2024-05-08T11:13:39.984134Z","shell.execute_reply":"2024-05-08T11:13:40.384063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Yılın 1. dönemi ile 4. dönemi diğer dönemlere göre daha büyük medyan değerine sahiptir.\n\n----------------------------------------------------------------------------------------------------\n\n- Period 1 and period 4 of the year have larger median values than the other periods.","metadata":{}},{"cell_type":"markdown","source":"## Moving Averages","metadata":{}},{"cell_type":"code","source":"# Display 24 hours moving averages and actual values for Global_active_power\nplot_moving_average(dataframe = df_train, window = 24)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:40.386482Z","iopub.execute_input":"2024-05-08T11:13:40.386813Z","iopub.status.idle":"2024-05-08T11:13:40.841345Z","shell.execute_reply.started":"2024-05-08T11:13:40.386784Z","shell.execute_reply":"2024-05-08T11:13:40.84023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Global_active_power özelliği için 24 saatlik ortalamalar ile gerçek değerler birbiri ile oldukça örtüşmektedir.\n\n------------------------------------------------------------------------------------------------------\n\n- For the global_active_power feature, the 24-hour averages and the actual values overlap quite well.","metadata":{}},{"cell_type":"markdown","source":"## Solar Features, Turbidity","metadata":{}},{"cell_type":"markdown","source":"![](https://firstgreenconsulting.wordpress.com/wp-content/uploads/2012/04/dni-dhi-ghi.jpg)\n\n[Kaynak](https://firstgreenconsulting.wordpress.com/2012/04/26/differentiate-between-the-dni-dhi-and-ghi/)\n\n\n**DNI**\n\nDoğrudan Normal Işınım (DNI), gökyüzündeki mevcut konumunda güneşin yönünden düz bir çizgide gelen ışınlara her zaman dik (veya normal) tutulan bir yüzey tarafından birim alan başına alınan güneş radyasyonu miktarıdır. Tipik olarak, bir yüzeyi gelen radyasyona normal tutarak yıllık olarak aldığı ışınım miktarını en üst düzeye çıkarabilirsiniz. Bu miktar, güneşin konumunu takip eden yoğunlaştırılmış güneş enerjisi tesisatları ve tesisatları için özellikle ilgi çekicidir.\n\n\n**DHI**\n\nDağınık Yatay Işınım (DHI), güneşten doğrudan bir yolla gelmeyen, ancak atmosferdeki moleküller ve parçacıklar tarafından saçılan ve her yönden eşit olarak gelen bir yüzey (herhangi bir gölge veya gölgeye maruz kalmayan) tarafından birim alan başına alınan radyasyon miktarıdır\n\n\n**GHI**\n\nKüresel Yatay Işınım (GHI), yere yatay bir yüzey tarafından yukarıdan alınan toplam kısa dalga radyasyon miktarıdır. Bu değer fotovoltaik tesisler için özellikle ilgi çekicidir ve hem Doğrudan Normal Işınım (DNI) hem de Dağınık Yatay Işınım (DHI) içerir.\n\nGlobal Horizontal (GHI) = Direct Normal (DNI) X cos(θ) + Diffuse Horizontal (DHI)\n\n\n\n**Turbidity**\n\nBulanıklık, havanın genel aerosol içeriğini (toz, nem, buz, sis) belirler. Gökyüzü görünümünü kolayca tanımlamak için kullanılır ve güneşin ve gökyüzünün rengini etkiler. Bulanıklık değerleri 1 ila 10 arasında değişir: 2: Çok berrak, Arktik benzeri bir gökyüzü verir.\n\n[Kaynak](https://help.autodesk.com/view/ARNOL/ENU/?guid=arnold_core_ac_physical_sky_html)\n\n-----------------------------------------------------------------------------------------------------------------------------------\n\n**DNI**\n\nDirect Normal Irradiance (DNI) is the amount of solar radiation received per unit area by a surface that is always kept perpendicular (or normal) to the incident rays in a straight line from the direction of the sun at its current position in the sky.Typically, you can maximize the amount of radiation a surface receives annually by keeping it normal to the incoming radiation. This quantity is of particular interest for concentrated solar installations and installations that track the position of the sun.\n\n**DHI**\n\nDiffuse Horizontal Irradiance (DHI) is the amount of radiation received per unit area by a surface (not exposed to any shadow or shade) that does not come from the sun in a direct path, but is scattered by molecules and particles in the atmosphere and comes from all directions equally\n\n**GHI**\n\nGlobal Horizontal Irradiance (GHI) is the total amount of shortwave radiation received from above by a surface horizontal to the ground. This value is of particular interest for photovoltaic installations and includes both Direct Normal Irradiance (DNI) and Diffuse Horizontal Irradiance (DHI).\n\nGlobal Horizontal (GHI) = Direct Normal (DNI) X cos(θ) + Diffuse Horizontal (DHI)\n\n**Turbidity**\n\nTurbidity determines the overall aerosol content of the air (dust, moisture, ice, fog).It is used to easily identify the appearance of the sky and affects the color of the sun and sky. Turbidity values range from 1 to 10: 2: Gives a very clear, Arctic-like sky.\n\n[Source](https://help.autodesk.com/view/ARNOL/ENU/?guid=arnold_core_ac_physical_sky_html)\n\n------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"![](data:image/png;base64,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)\n\n\n**Solar Zenith Angle**\n\nUydu tabanlı bir cihazdan Dünya yüzeyindeki belirli bir noktayı gözlemlerken, Güneş Zenit Açısı (SZA) yerel zenit (yani yerdeki noktanın hemen üstünde) ile o noktadan Güneş'e olan görüş hattı arasındaki açıdır. Bu, Güneş gökyüzünde ne kadar yüksekse SZA'nın o kadar düşük olduğu anlamına gelir. Grafikteki diğer açı, yerel zenit ile uyduya giden görüş hattı arasındaki açı, Görüş Zenit Açısı olarak adlandırılır.\n\n\n\n**Azimuth**\n\nAzimut, bir azimut dairesi üzerinde kuzeyden saat yönünde derece cinsinden ölçülen yöndür. Bir azimut dairesi 360 dereceden oluşur. Doksan derece doğuya, 180 derece güneye, 270 derece batıya ve 360 derece ve 0 derece kuzeye karşılık gelir.\n\n\n\n**Equation_of_time**\n\nGüneş tarafından ölçülen zaman ile bizim saatlerimiz tarafından ölçülen zaman aynı değildir. İkisi arasındaki farka zaman denklemi denir. [Kaynak](https://www.timeanddate.com/astronomy/equation-of-time.html)\n\n----------------------------------------------------------------------------------------------------\n\n**Solar Zenith Angle**\n\nWhen observing a specific point on the Earth's surface from a satellite-based instrument, the Solar Zenith Angle (SZA) is the angle between the local zenith (i.e. just above the point on the ground) and the line of sight from that point to the Sun. This means that the higher the Sun is in the sky, the lower the SZA. The other angle on the graph, the angle between the local zenith and the line of sight to the satellite, is called the Solar Zenith Angle.\n\n**Azimuth**\n\nAzimuth is the direction measured in degrees clockwise from north on an azimuth circle.An azimuth circle consists of 360 degrees.Ninety degrees corresponds to east, 180 degrees to south, 270 degrees to west and 360 degrees and 0 degrees to north.\n\n**Equation_of_time**\n\nThe time measured by the sun is not the same as the time measured by our clocks.The difference between the two is called the equation of time. [Source](https://www.timeanddate.com/astronomy/equation-of-time.html)","metadata":{}},{"cell_type":"code","source":"latitude =  48.7764400\nlongitude = 2.2902600\ntz = \"Europe/Berlin\"\ncity = \"Sceaux\"\nstart = \"2006-01-01\"\nend = \"2010-11-27\"\n\nsolpos, truetracking_position, turbidity = advanced_solar_features(latitude,\n                                                                      longitude,\n                                                                      tz,\n                                                                      city,\n                                                                      start,\n                                                                      end)\n\n\ncs = solar_features(latitude,\n                      longitude,\n                      tz,\n                      city,\n                      start,\n                      end)\ncs.tail()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:40.842829Z","iopub.execute_input":"2024-05-08T11:13:40.843206Z","iopub.status.idle":"2024-05-08T11:13:42.231468Z","shell.execute_reply.started":"2024-05-08T11:13:40.843175Z","shell.execute_reply":"2024-05-08T11:13:42.230368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To see what the turbidity data set looks like\nturbidity.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:42.233163Z","iopub.execute_input":"2024-05-08T11:13:42.234209Z","iopub.status.idle":"2024-05-08T11:13:42.245391Z","shell.execute_reply.started":"2024-05-08T11:13:42.234166Z","shell.execute_reply":"2024-05-08T11:13:42.244248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To see what the truetracking_position data set looks like\ntruetracking_position.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:13:42.246849Z","iopub.execute_input":"2024-05-08T11:13:42.247539Z","iopub.status.idle":"2024-05-08T11:13:42.265084Z","shell.execute_reply.started":"2024-05-08T11:13:42.247498Z","shell.execute_reply":"2024-05-08T11:13:42.263968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To see what the solpos data set looks like\nsolpos.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:42.26655Z","iopub.execute_input":"2024-05-08T11:13:42.267565Z","iopub.status.idle":"2024-05-08T11:13:42.282648Z","shell.execute_reply.started":"2024-05-08T11:13:42.267525Z","shell.execute_reply":"2024-05-08T11:13:42.281475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Meteostat","metadata":{}},{"cell_type":"markdown","source":"[Kaynak](https://dev.meteostat.net/python/hourly.html#data-structure)\n\n**Dwpt**\n\nÇiğlenme Noktası - Atmosferik nemin bir ölçüsüdür. Doygunluğa ulaşmak için havanın soğutulması gereken sıcaklıktır (hava basıncı ve nem içeriğinin sabit olduğu varsayılır). [Kaynak](https://w1.weather.gov/glossary/index.php?word=dew+point)\n\n**Rhum**\n\nHava doymuş olsaydı mevcut olacak miktara göre mevcut atmosferik nem miktarının yüzde olarak ifade edilen bir oranıdır. İkinci miktar sıcaklığa bağlı olduğundan, bağıl nem hem nem içeriğinin hem de sıcaklığın bir fonksiyonudur.\n\n**Prpc**\n\nmm cinsinden bir saatlik yağış toplamı\n\n**wdir**\n\nDerece (°) cinsinden ortalama rüzgar yönü\n\n**wspd**\n\nThe average wind speed in km/h\n\n**press**\n\nhPa cinsinden deniz seviyesindeki ortalama hava basıncı\n\n--------------------------------------------------------------------------------------------\n\n[Source](https://dev.meteostat.net/python/hourly.html#data-structure)\n\n**Dwpt**\n\nDew Point - A measure of atmospheric humidity. It is the temperature at which air must be cooled to reach saturation (assuming constant air pressure and moisture content). [Source](https://w1.weather.gov/glossary/index.php?word=dew+point)\n\n**Rhum**\n\nIt is a ratio, expressed as a percentage, of the amount of atmospheric moisture present relative to the amount that would be present if the air were saturated. Since the latter quantity depends on temperature, relative humidity is a function of both moisture content and temperature.\n\n**Prpc**\n\nOne-hour rainfall total in mm\n\n**wdir**\n\nAverage wind direction in degrees (°)\n\n**wspd**\n\nThe average wind speed in km/h\n\n**press**\n\nAverage air pressure at sea level in hPa","metadata":{}},{"cell_type":"code","source":"weather = meteostat_weather_data(latitude,\n                                longitude,\n                                start,\n                                end)\nweather.tail()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:42.284333Z","iopub.execute_input":"2024-05-08T11:13:42.284879Z","iopub.status.idle":"2024-05-08T11:13:43.44432Z","shell.execute_reply.started":"2024-05-08T11:13:42.284822Z","shell.execute_reply":"2024-05-08T11:13:43.443256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merge train and test set with cs, solpos, ...\ndf_train, df_test = merge_dataframes([df_train, df_test])\ndf_train","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:43.445771Z","iopub.execute_input":"2024-05-08T11:13:43.446376Z","iopub.status.idle":"2024-05-08T11:13:43.656257Z","shell.execute_reply.started":"2024-05-08T11:13:43.446331Z","shell.execute_reply":"2024-05-08T11:13:43.65513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Detecting Outlier Values","metadata":{}},{"cell_type":"markdown","source":"Here we will identify outlier values and try to understand when outlier values occur","metadata":{}},{"cell_type":"code","source":"#Create population distribution for Global_active_power\ndfit = distfit(distr = \"popular\")\nresults = dfit.fit_transform(df_train[\"Global_active_power\"])\npredict_result = dfit.predict(df_train[\"Global_active_power\"].values, alpha = 0.05, multtest = None)\n#Get outlier values\ndf_outlier = pd.DataFrame(predict_result[\"df\"])\ndf_outlier.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:43.657773Z","iopub.execute_input":"2024-05-08T11:13:43.658225Z","iopub.status.idle":"2024-05-08T11:13:46.787302Z","shell.execute_reply.started":"2024-05-08T11:13:43.658194Z","shell.execute_reply":"2024-05-08T11:13:46.786281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_2006 = df_train[df_train.index.year == 2006]\ndf_2007 = df_train[df_train.index.year == 2007]\ndf_2008 = df_train[df_train.index.year == 2008]\n#df_2009 = df_train[df_train.index.year == 2009]\n#df_2010 = df_train[df_train.index.year == 2010]\n\nfig, ax = plt.subplots(nrows = 2, ncols = 1, figsize = (20, 12))\nfor i, dataframe in enumerate([df_2007, df_2008]):\n    # Make prediction\n    dfit.predict(dataframe[\"Global_active_power\"].values, alpha=0.05, multtest=None)\n    # Line plot with data points outside the confidence interval.\n    dfit.lineplot(dataframe[\"Global_active_power\"], ax = ax[i])\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:13:46.78867Z","iopub.execute_input":"2024-05-08T11:13:46.789006Z","iopub.status.idle":"2024-05-08T11:15:00.806056Z","shell.execute_reply.started":"2024-05-08T11:13:46.788979Z","shell.execute_reply":"2024-05-08T11:15:00.805048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking into upper outlier values and lower outlier values\ndf_upper_outlier = df_train.iloc[df_outlier[df_outlier[\"y_pred\"] == \"up\"].index]\ndf_lower_outlier = df_train.iloc[df_outlier[df_outlier[\"y_pred\"] == \"down\"].index]\nprint(\"Head of Dataframe for Upper Outliers\")\nprint(df_upper_outlier.head())\nprint(\"*\"*100)\nprint(\"Head of Dataframe for Lower Outliers\")\nprint(df_lower_outlier.head())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:00.807343Z","iopub.execute_input":"2024-05-08T11:15:00.807961Z","iopub.status.idle":"2024-05-08T11:15:00.860442Z","shell.execute_reply.started":"2024-05-08T11:15:00.807927Z","shell.execute_reply":"2024-05-08T11:15:00.859311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_pie = [\n    \"Month\",\n    \"Day_ofweek\",\n    \"Hour\"\n]\n\n#Plot pie chart for upper_outlier\nplot_pie(df_upper_outlier, columns_pie)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:09:54.29542Z","iopub.execute_input":"2024-05-08T13:09:54.295821Z","iopub.status.idle":"2024-05-08T13:09:54.880222Z","shell.execute_reply.started":"2024-05-08T13:09:54.29578Z","shell.execute_reply":"2024-05-08T13:09:54.878932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot pie chart for lower_outlier\nplot_pie(df_lower_outlier, columns_pie, title = \"Lower\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T13:09:59.277851Z","iopub.execute_input":"2024-05-08T13:09:59.279123Z","iopub.status.idle":"2024-05-08T13:09:59.862085Z","shell.execute_reply.started":"2024-05-08T13:09:59.27907Z","shell.execute_reply":"2024-05-08T13:09:59.860939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Outlier değerlerin yüksekleri incelendiğinde\n    - Ay olarak: Ekim Ayından Mart ayına kadar değerler büyük yüzdeyi kapsamıştır. Soğuk hava şartları elektrik tüketimini artırdığını görüyoruz.\n    - Haftanın Günü olarak: Cumartesi ve Pazar günleri diğer günlere göre oldukça sık görülmüştür. Hafta sonları insanlar evlerinde olduğundan elektrik tüketiminin arttığını görüyoruz.\n    - Saat olarak: 17'den 21'e kadarki saatler diğer saatlere göre oldukça sık görülmüştür. İnsanlar işten gelip evde ayakta kaldığı zamanlara denk gelmektedir.\n    \n \n- Outlier değerlerin düşükleri incelendiğinde\n     - Ay olarak: Mayıs Ayından Eylül ayına kadar değerler büyük yüzdeyi kapsamıştır. Sıcak hava şartlarının elektrik tüketimini azalttığını görüyoruz.\n     - Haftanın Günü olarak: Neredeyse hepsi aynı yüzdeyi kapsamıştır.\n     - Saat olarak: Gece 1'den Sabah 6'ya kadarki saatler diğer saatlere göre oldukça sık görülmüştür. İnsanların uyuduğu zamana denk gelmektedir.\n \n --------------------------------------------------------------------------------------------\n \n- When the high outlier values are examined\n    - By month: Values from October to March cover the largest percentage. We see that cold weather conditions increase electricity consumption.\n    - As Day of the Week: Saturdays and Sundays are more common than other days. Since people are at home on weekends, we see that electricity consumption increases.\n    - Time of day: The hours between 17:00 and 21:00 are more frequent than other hours. It coincides with the times when people come from work and stay at home.\n    \n \n- When the low outlier values are analyzed\n     - By month: Values from May to September cover the largest percentage. We see that warm weather conditions reduce electricity consumption.\n     - By Day of the Week: Almost all covered the same percentage.\n     - In hours: The hours from 1 am to 6 am were more frequent than other hours. It coincides with the time when people are sleeping.\n ","metadata":{}},{"cell_type":"markdown","source":"Hatırlarsak 2008 yılının Ağustos ayındaki diğer ayalra göre oldukça düşük çıkmış idi. İstersek bu değerleri trend bozulmasın diye değiştirebiliriz. Ancak değiştirdikten sonra modellerin performasnını düşürdüğünü gördüm ve bu yüzden uygulamadım\n\n----------------------------------------------------------------------------------------------\n\nIf we remember, August 2008 was considerably lower than the other months of 2008. If we want, we can change these values so as not to distort the trend. However, after changing it, I found that it decreased the performance of the models and therefore I did not apply it.","metadata":{}},{"cell_type":"code","source":"if config.change_2008August_values:\n    #Change 2008 august values with mean values grouped by Hour, Day_ofweek and Month\n    first_cond = (df_train.index.year == 2008)\n    second_cond = (df_train.index.month == 8)\n    \n    a = df_train.loc[~(first_cond & second_cond)].groupby([\"Hour\", \"Day_ofweek\", \"Month\"]).mean().reset_index(drop = False)\n    a = a[a.Month == 8]\n    change_cols = [\n        \"Global_active_power\",\n        \"Global_reactive_power\",\n        \"Voltage\",\n        \"Sub_metering_1\",\n        \"Sub_metering_2\",\n        \"Sub_metering_3\"\n    ]\n    df_train.loc[first_cond & second_cond, change_cols] = pd.merge(df_train.loc[first_cond & second_cond, change_cols + [\"Hour\", \"Day_ofweek\"]], a, on = [\"Hour\", \"Day_ofweek\"], how = \"left\", suffixes = (\"_old\", \"\"))[change_cols].values","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:01.98271Z","iopub.execute_input":"2024-05-08T11:15:01.983086Z","iopub.status.idle":"2024-05-08T11:15:01.99158Z","shell.execute_reply.started":"2024-05-08T11:15:01.983055Z","shell.execute_reply":"2024-05-08T11:15:01.990355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"if config.sum_sub_meterings:\n    for dataframe in [df_train, df_test]:\n        #Add sum of Sub_metering_1, Sub_metering_2 and Sub_metering_3\n        dataframe[\"Sum_Sub_Meterings\"] = dataframe[\"Sub_metering_1\"] + dataframe[\"Sub_metering_2\"] + dataframe[\"Sub_metering_3\"]\n\n    #Drop Sub_metering_1, Sub_metering_2 and Sub_metering_3 from train and test set\n    df_train = df_train.drop([\"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\"], axis = 1)\n    df_test = df_test.drop([\"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\"], axis = 1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:01.992937Z","iopub.execute_input":"2024-05-08T11:15:01.99391Z","iopub.status.idle":"2024-05-08T11:15:02.011538Z","shell.execute_reply.started":"2024-05-08T11:15:01.993849Z","shell.execute_reply":"2024-05-08T11:15:02.010363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.add_moving_averages:\n    def moving_average(dataframe: pd.DataFrame, \n                       windows:list):\n        \"\"\"\n            Veri setine istediğimiz sayıda Global_active_power özelliğinin ortalamasını eklemek için oluşturduk.\n        \"\"\"\n        for window in windows:\n            dataframe[f\"Global_active_power_rolling_{window}\"] = dataframe[\"Global_active_power\"].shift(1).rolling(window = window, min_periods = 1).mean()\n        \n        return dataframe\n    \n    for dataframe in [df_train, df_test]:\n        #Add moving averages\n        df_train = moving_average(df_train, [24, 48, 72, 96, 120])\n        df_test = moving_average(df_test, [24, 48, 72, 96, 120])\n        \n        df_train = df_train.dropna()  # Because of 1 shift in moving_average fuction, there will be 1 NaN value\n        df_test = df_test.dropna()   # Because of 1 shift in moving_average fuction, there will be 1 NaN value","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:02.013965Z","iopub.execute_input":"2024-05-08T11:15:02.014405Z","iopub.status.idle":"2024-05-08T11:15:02.060466Z","shell.execute_reply.started":"2024-05-08T11:15:02.014368Z","shell.execute_reply":"2024-05-08T11:15:02.059543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dimensionality Reduction","metadata":{}},{"cell_type":"code","source":"if config.use_pca:\n    exclude_cols = [\n                   \"Hour\",\n                   \"Day_ofweek\",\n                   \"Day_ofmonth\",\n                   \"Day_ofyear\",\n                   \"Week_ofyear\",\n                   \"Month\",\n                   \"Quarter\",\n                   \"Year\",\n                   \"Global_active_power\"\n                   ]\n    include_cols = [col for col in df_train.columns if not col in exclude_cols]\n    #Create PCA Object\n    pca = PCA(whiten = True)\n    #Fit and Transform cols\n    x_PCA =  pca.fit(df_train[include_cols])\n    #Create figure for graph\n    plt.figure(figsize=(18,6))\n    #Plot lineplot for explained_variance_ratio_\n    sns.lineplot(np.cumsum(x_PCA.explained_variance_ratio_))\n    #Plot horizantal line at 0.99\n    plt.axhline(0.99, c=\"r\")\n    # Set x-axis tick locations and labels\n    plt.xticks(range(0, 22, 1))\n    #Set x_label\n    plt.xlabel(\"number of components\")\n    #Set y_label\n    plt.ylabel(\"cumulative explained variance\")\n    #Display graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:02.062037Z","iopub.execute_input":"2024-05-08T11:15:02.062385Z","iopub.status.idle":"2024-05-08T11:15:03.699429Z","shell.execute_reply.started":"2024-05-08T11:15:02.062353Z","shell.execute_reply":"2024-05-08T11:15:03.698194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kategorik verileri dışarı çıkardığımızda  yüzde 99'luk bilgi için 3 boyutlu PCA yeterlidir.\n\n--------------------------------------------------------------------------------\n\nWhen we exclude categorical data, 3D PCA is sufficient for 99 percent information.","metadata":{}},{"cell_type":"code","source":"if config.use_pca:\n\n    # Created PCA with 3 Dimensional\n    pca = PCA(n_components = 3, whiten = True)\n\n    #Create pca values from train and test set\n    train_PCA = pca.fit_transform(df_train[include_cols])\n    test_PCA = pca.transform(df_test[include_cols])\n\n    #Remove include cols from train and test set\n    df_train = df_train.drop(include_cols, axis = 1)\n    df_test = df_test.drop(include_cols, axis = 1)\n\n\n    #Concat pca values with train and test set\n    df_train[[\"PCA_1\", \"PCA_2\", \"PCA_3\"]] = train_PCA\n    df_test[[\"PCA_1\", \"PCA_2\", \"PCA_3\"]] = test_PCA\n    df_train.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.701194Z","iopub.execute_input":"2024-05-08T11:15:03.701543Z","iopub.status.idle":"2024-05-08T11:15:03.817165Z","shell.execute_reply.started":"2024-05-08T11:15:03.701513Z","shell.execute_reply":"2024-05-08T11:15:03.815582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODELING","metadata":{}},{"cell_type":"code","source":"# Create target feature for predict after 24 hours\ndf[\"Target\"] = df[\"Global_active_power\"].shift(-24)\ndf_train[\"Target\"] = df.loc[df.index <= \"2010-06-01\", \"Target\"].copy()\ndf_test[\"Target\"] = df.loc[df.index > \"2010-06-01\", \"Target\"].copy()\n\n\ndf_test = df_test.dropna()\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:15:03.824612Z","iopub.execute_input":"2024-05-08T11:15:03.825697Z","iopub.status.idle":"2024-05-08T11:15:03.882919Z","shell.execute_reply.started":"2024-05-08T11:15:03.825659Z","shell.execute_reply":"2024-05-08T11:15:03.881438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tahmin etmek istediğimiz \"Global_active_power\" özelliği log normal dağılımı göstermekte. Tahminin iyileşmesi adına özelliğin logaritmasını aldıktan sonra normal dağılıma çevireceğim. \n\n-------------------------------------------------------------------------------------------------------------\n\nThe “Global_active_power” feature we want to estimate is log normal distribution. To improve the estimation, I will take the logarithm of the feature and convert it to normal distribution. ","metadata":{}},{"cell_type":"code","source":"#Log of Global_active_power\ndf_train[\"Log_oftarget\"] = np.log(df_train[\"Global_active_power\"])\ndf_test[\"Log_oftarget\"] = np.log(df_test[\"Global_active_power\"])\n\n#Normalization of Global_active_power\nstandart_scaler = StandardScaler()\ndf_train[\"Normalization_oftarget\"] = standart_scaler.fit_transform(df_train[\"Log_oftarget\"].values.reshape(-1,1))\ndf_test[\"Normalization_oftarget\"] = standart_scaler.transform(df_test[\"Log_oftarget\"].values.reshape(-1, 1))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.89011Z","iopub.execute_input":"2024-05-08T11:15:03.894662Z","iopub.status.idle":"2024-05-08T11:15:03.915769Z","shell.execute_reply.started":"2024-05-08T11:15:03.894586Z","shell.execute_reply":"2024-05-08T11:15:03.914195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change Week_ofyear data type\ndf_train[\"Week_ofyear\"] = df_train[\"Week_ofyear\"].astype(int)\ndf_test[\"Week_ofyear\"] = df_test[\"Week_ofyear\"].astype(int)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.923401Z","iopub.execute_input":"2024-05-08T11:15:03.92733Z","iopub.status.idle":"2024-05-08T11:15:03.933882Z","shell.execute_reply.started":"2024-05-08T11:15:03.927274Z","shell.execute_reply":"2024-05-08T11:15:03.932994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create X and y dataset from train and test set\nX_train = df_train.drop([\"Target\",\"Log_oftarget\", \"Normalization_oftarget\"], axis = 1)\ny_train = df_train[\"Normalization_oftarget\"].reset_index(drop = True)\n\nX_test = df_test.drop([\"Target\", \"Log_oftarget\", \"Normalization_oftarget\"], axis = 1)\ny_test = df_test[\"Target\"].reset_index(drop = True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.935653Z","iopub.execute_input":"2024-05-08T11:15:03.937456Z","iopub.status.idle":"2024-05-08T11:15:03.949902Z","shell.execute_reply.started":"2024-05-08T11:15:03.937414Z","shell.execute_reply":"2024-05-08T11:15:03.948945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create TimeSeriesSplit\ncv = TimeSeriesSplit(n_splits = config.n_splits)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:15:03.951755Z","iopub.execute_input":"2024-05-08T11:15:03.952159Z","iopub.status.idle":"2024-05-08T11:15:03.958499Z","shell.execute_reply.started":"2024-05-08T11:15:03.952128Z","shell.execute_reply":"2024-05-08T11:15:03.957397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGB","metadata":{}},{"cell_type":"code","source":"cat_features = [\n    \"Hour\",\n    \"Day_ofweek\",\n    \"Day_ofmonth\",\n    \"Day_ofyear\",\n    \"Week_ofyear\",\n    \"Month\",\n    \"Quarter\",\n    \"Year\"\n]\n#Change cat features data type to category\nX_train[cat_features] = X_train[cat_features].astype(\"category\")\nX_test[cat_features] = X_test[cat_features].astype(\"category\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.959532Z","iopub.execute_input":"2024-05-08T11:15:03.959875Z","iopub.status.idle":"2024-05-08T11:15:03.98489Z","shell.execute_reply.started":"2024-05-08T11:15:03.959831Z","shell.execute_reply":"2024-05-08T11:15:03.983897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_XGB = {\n    \"booster\": \"gbtree\",\n    #\"device\": \"gpu\", #if you want to use gpu\n    \"max_depth\": 2,\n    \"lambda\": 1, #L2 regularization\n    \"tree_method\": \"hist\", #Faster histogram optimized approximate greedy algorithm.\n    \"grow_policy\": \"depthwise\", #Controls a way new nodes are added to the tree.\n    \"enable_categorical\": True,\n    \"objective\": \"reg:squarederror\",\n    \"eval_metric\": \"rmse\",\n    #\"n_estimators\" : 200,\n    \"learning_rate\": 0.01,\n    \"early_stopping_rounds\" : 500\n    \n}\npredicters = {\n    \"XGBRegressor\" : xgb.XGBRegressor(**params_XGB)\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.98617Z","iopub.execute_input":"2024-05-08T11:15:03.986498Z","iopub.status.idle":"2024-05-08T11:15:03.993168Z","shell.execute_reply.started":"2024-05-08T11:15:03.986469Z","shell.execute_reply":"2024-05-08T11:15:03.992205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(\n                X: pd.DataFrame,\n                y: pd.Series,\n                X_test: pd.DataFrame,\n                y_test : pd.Series,\n                cv: TimeSeriesSplit,\n                predicters: dict,\n                \n):\n    mean_squared_error_scores = list()\n    models = list()\n    test_preds = list()\n    for name, model in predicters.items():\n        print(f\"Evaluating {name}...\")\n        fold_test_mse_scores = list()\n        elapsed_time = 0\n        for idx, (train_idx, val_idx) in enumerate(cv.split(X=X, y = y)):\n            start_time = time.time()\n            \n            print(f\"train_idx: {train_idx}\")\n            print(f\"val_idx: {val_idx}\")\n\n            X_train = X.iloc[train_idx].copy()\n            y_train = y.iloc[train_idx].copy()\n            X_val = X.iloc[val_idx].copy()\n            y_val = y.iloc[val_idx].copy()\n            \n\n            model.fit(X_train,\n                        y_train,\n                        eval_set=[(X_train, y_train),(X_val, y_val)],\n\n                        verbose=250)\n        \n        \n            test_pred = model.predict(X_test)\n            test_pred = np.exp(standart_scaler.inverse_transform(test_pred.reshape(-1,1)))\n            test_preds.append(test_pred)\n            \n            fold_test_mse_score = mean_squared_error(y_true = y_test, y_pred = test_pred )\n            print(f\"\\n{name} Model Fold {idx + 1} Mean Squred Error for Test Set:{fold_test_mse_score}\")\n\n\n            fold_test_mse_scores.append(fold_test_mse_score)\n\n            #model_file_path = f\"{name}_fold_{idx + 1}.pkl\"\n            #joblib.dump(model, os.path.join(config.model_path, model_file_path))\n            models.append(model)\n\n            end_time = time.time()\n            elapsed = end_time - start_time\n            print(f\"Time to {name} Model for Fold {idx + 1}: {elapsed}\")\n            print(\"*\"*120)\n\n            elapsed_time += elapsed\n\n        print(f\"{name} model run time is : {elapsed_time} seconds\")\n        print(f\"{name} model has a mean of Mean Squared Error Score for Test Set: {np.mean(fold_test_mse_scores)}\")\n        print(\"*\"*120)\n\n        mean_squared_error_scores.append(fold_test_mse_scores)\n\n    return fold_test_mse_scores, models, test_preds","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:03.99456Z","iopub.execute_input":"2024-05-08T11:15:03.994922Z","iopub.status.idle":"2024-05-08T11:15:04.010766Z","shell.execute_reply.started":"2024-05-08T11:15:03.994888Z","shell.execute_reply":"2024-05-08T11:15:04.009387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_test_mse_scores_xgb, models_xgb, test_preds_xgb = create_model(X_train,\n                                                                        y_train,\n                                                                        X_test,\n                                                                        y_test,\n                                                                        cv = cv,\n                                                                        predicters = predicters)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:15:04.012249Z","iopub.execute_input":"2024-05-08T11:15:04.012589Z","iopub.status.idle":"2024-05-08T11:15:05.568306Z","shell.execute_reply.started":"2024-05-08T11:15:04.01256Z","shell.execute_reply":"2024-05-08T11:15:05.567424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create figure and axes for grap\nfig, ax = plt.subplots(nrows = 1, ncols = config.n_splits, figsize = (25, 6))\nfor i, model in enumerate(models_xgb):\n    #Get evaluation results\n    result = model.evals_result()\n    #Create figure for graph\n    plt.figure(figsize = (10, 6))\n    #Plot lineplot for train and validation set\n    sns.lineplot(result[\"validation_0\"][\"rmse\"], label = \"Train\", ax=ax[i])\n    sns.lineplot(result[\"validation_1\"][\"rmse\"], label = \"Validation\", ax = ax[i])\n    \n    #Set title for graph\n    ax[i].set_title(f\"RMSE Loss for Fold {i + 1} \", \n              fontsize = 15, \n              fontweight = 15)\n    #Set x_axis and y_axis label\n    ax[i].set_ylabel(\"RMSE\")\n    ax[i].set_xlabel(\"Epochs\")\n\n#Display graph\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:05.569686Z","iopub.execute_input":"2024-05-08T11:15:05.57063Z","iopub.status.idle":"2024-05-08T11:15:07.02546Z","shell.execute_reply.started":"2024-05-08T11:15:05.570594Z","shell.execute_reply":"2024-05-08T11:15:07.024303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP","metadata":{}},{"cell_type":"code","source":"#Create one hot encoder\nencoder = OneHotEncoder(sparse_output = False)\n\n#One hot encoder to train set\nresults_train = encoder.fit_transform(X_train[cat_features])\nX_train = pd.concat([X_train, pd.DataFrame(results_train, index = df_train.index)], axis = 1)\nX_train = X_train.drop(cat_features, axis = 1)\n\n#One hot encoder the test set\nresults_test = encoder.transform(X_test[cat_features])\nX_test = pd.concat([X_test, pd.DataFrame(results_test, index = df_test.index)], axis = 1)\nX_test = X_test.drop(cat_features, axis = 1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:07.027429Z","iopub.execute_input":"2024-05-08T11:15:07.027828Z","iopub.status.idle":"2024-05-08T11:15:07.61063Z","shell.execute_reply.started":"2024-05-08T11:15:07.027795Z","shell.execute_reply":"2024-05-08T11:15:07.609339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n#regularizers\nfrom tensorflow.keras.layers import Dropout # one of the best regularizers\nfrom tensorflow.keras.regularizers import l1,l2,l1_l2\n\n#optimizers\nfrom tensorflow.keras.optimizers import Adam, Adadelta, RMSprop\n#metrics\nfrom tensorflow.keras.metrics import MeanSquaredError","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:07.612617Z","iopub.execute_input":"2024-05-08T11:15:07.613112Z","iopub.status.idle":"2024-05-08T11:15:22.161064Z","shell.execute_reply.started":"2024-05-08T11:15:07.613069Z","shell.execute_reply":"2024-05-08T11:15:22.159717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n#Add input layer\nmodel.add(Flatten(input_shape = (X_train.shape[1],)))\n#Add first hidden layer\nmodel.add(Dense(16, activation = \"leaky_relu\", kernel_initializer='he_normal', kernel_regularizer = l2(0.02))) #kernel_regularizer = l2(0.01)\n#Add second hidden layer\nmodel.add(Dense(4, activation = \"leaky_relu\", kernel_regularizer = l2(0.01))) #kernel_regularizer = l2(0.01)\n#Add third hidden layer\n#model.add(Dense(8, activation = \"leaky_relu\"))\n#Add output layer\nmodel.add(Dense(1, activation = \"linear\"))\n\n#Create early stopping conditions for MLP model\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 20, restore_best_weights=True, min_delta = 0.005, start_from_epoch = 50)\n\nmodel.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:22.163028Z","iopub.execute_input":"2024-05-08T11:15:22.163973Z","iopub.status.idle":"2024-05-08T11:15:22.299066Z","shell.execute_reply.started":"2024-05-08T11:15:22.163926Z","shell.execute_reply":"2024-05-08T11:15:22.297879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_FCL_model(\n                X:pd.DataFrame,\n                y: pd.Series,\n                X_test: pd.DataFrame,\n                y_test: pd.Series,\n                cv:TimeSeriesSplit,\n                model: tf.keras.models,\n                early_stopping: tf.keras.callbacks.EarlyStopping\n):\n    \n    #mean_squared_error_scores = list()\n    models = list()\n    test_preds = list()\n    fold_test_mse_scores = list()\n    elapsed_time = 0\n    histories = list()\n    \n    for idx, (train_idx, val_idx) in enumerate(cv.split(X = X, y = y)):\n        start_time = time.time()\n        \n        X_train = np.array(X.iloc[train_idx].values.copy())\n        y_train = np.array(y.iloc[train_idx].values.copy())\n        \n        X_val = np.array(X.iloc[val_idx].values.copy())\n        y_val = np.array(y.iloc[val_idx].values.copy())\n        \n       \n        model.compile(\n            optimizer = RMSprop(learning_rate = 0.0001),\n            loss = \"mse\",\n            metrics = [MeanSquaredError]\n            \n        )\n        \n        history = model.fit(X_train, \n                            y_train, \n                            epochs = 1000, \n                            batch_size = 32, \n                            validation_data = (X_val, y_val), \n                            callbacks = [early_stopping], \n                            verbose = 2\n                           )\n        \n        #Add history to list\n        histories.append(history)\n        \n        test_pred = model.predict(X_test)\n        test_pred = np.exp(standart_scaler.inverse_transform(test_pred))\n        test_preds.append(test_pred)\n        \n\n        fold_test_mse_score = mean_squared_error(y_true = y_test, y_pred = test_pred)\n        print(f\"\\nFully Connected Layer Model Fold {idx + 1} Mean Squred Error for Test Set:{fold_test_mse_score}\")\n        \n        fold_test_mse_scores.append(fold_test_mse_score)\n\n        #model_file_path = f\"{name}_fold_{idx + 1}.pkl\"\n        #joblib.dump(model, os.path.join(config.model_path, model_file_path))\n        models.append(model)\n\n        end_time = time.time()\n        elapsed = end_time - start_time\n        print(f\"Time to Fully Connected Layer Model for Fold {idx + 1}: {elapsed}\")\n        print(\"*\"*120)\n\n        elapsed_time += elapsed\n        \n    print(f\"Fully Connected Layer model run time is : {elapsed_time} seconds\")\n    print(f\"Fully Connected Layer model has a mean of Mean Squared Error Score for Test Set: {np.mean(fold_test_mse_scores)}\")\n    print(\"*\"*120)\n\n    #mean_squared_error_scores.append(fold_test_mse_scores)\n\n    return fold_test_mse_scores, models, histories, test_preds\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:22.311286Z","iopub.execute_input":"2024-05-08T11:15:22.312182Z","iopub.status.idle":"2024-05-08T11:15:22.327586Z","shell.execute_reply.started":"2024-05-08T11:15:22.312144Z","shell.execute_reply":"2024-05-08T11:15:22.326239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_test_mse_scores_fcl, models_fcl, histories_fcl, test_preds_fcl = create_FCL_model(X_train,\n                                                                        y_train,\n                                                                        X_test,\n                                                                        y_test,\n                                                                        cv = cv,\n                                                                        model = model,\n                                                                        early_stopping = early_stopping\n                                                                    )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T11:15:22.329028Z","iopub.execute_input":"2024-05-08T11:15:22.330065Z","iopub.status.idle":"2024-05-08T11:23:53.096977Z","shell.execute_reply.started":"2024-05-08T11:15:22.329936Z","shell.execute_reply":"2024-05-08T11:23:53.095712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 1, ncols = config.n_splits, figsize = (25, 6))\nfor i, history in enumerate(histories_fcl):\n    #Lineplot for train and validation loss\n    sns.lineplot(history.history[\"loss\"], label = \"Train\", color = \"blue\", ax = ax[i])\n    sns.lineplot(history.history[\"val_loss\"], label = \"Validation\", color = \"orange\", ax = ax[i])\n    \n    #Set title for graph\n    ax[i].set_title(f\"MSE Loss for Fold {i + 1} \", \n              fontsize = 15, \n              fontweight = 15)\n    #Set x_axis and y_axis label\n    ax[i].set_ylabel(\"MSE\")\n    ax[i].set_xlabel(\"Epochs\")\n\n#Display graph\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:23:53.098633Z","iopub.execute_input":"2024-05-08T11:23:53.099387Z","iopub.status.idle":"2024-05-08T11:23:54.619932Z","shell.execute_reply.started":"2024-05-08T11:23:53.099354Z","shell.execute_reply":"2024-05-08T11:23:54.618479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM","metadata":{}},{"cell_type":"markdown","source":"Son 24 saatin verilerini kullanarak 24 saat sonrasının verilerini tahmin etmeye çalışacağız.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import LSTM","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:23:54.621912Z","iopub.execute_input":"2024-05-08T11:23:54.622368Z","iopub.status.idle":"2024-05-08T11:23:54.628083Z","shell.execute_reply.started":"2024-05-08T11:23:54.622327Z","shell.execute_reply":"2024-05-08T11:23:54.626929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset_LSTM(dataframe:pd.DataFrame,\n                       first_target: str = \"Normalization_oftarget\",\n                       second_target: str = \"Normalization_oftarget\"):\n    \n    X = []\n    y = []\n    \n    for i in range(24, dataframe.shape[0]-24):\n        X.append(dataframe.iloc[i-24:i+1][first_target]) # Get last 24 hours values\n        y.append(dataframe.iloc[i+24][second_target])     #To predict after 24 hours\n    \n    #Convert to X_train and y_train to numpy arrays\n    X, y = np.array(X), np.array(y)\n\n    #Reshape the data\n    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n    \n    return X, y","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:23:54.629674Z","iopub.execute_input":"2024-05-08T11:23:54.630141Z","iopub.status.idle":"2024-05-08T11:23:54.645775Z","shell.execute_reply.started":"2024-05-08T11:23:54.6301Z","shell.execute_reply":"2024-05-08T11:23:54.644565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train =  create_dataset_LSTM(df_train)\nX_test, y_test = create_dataset_LSTM(df_test, second_target = \"Target\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:23:54.648679Z","iopub.execute_input":"2024-05-08T11:23:54.649074Z","iopub.status.idle":"2024-05-08T11:24:07.330632Z","shell.execute_reply.started":"2024-05-08T11:23:54.649041Z","shell.execute_reply":"2024-05-08T11:24:07.329446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the LSTM Model\nmodel = Sequential()\n#Add LSTM layer\nmodel.add(LSTM(16, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n#Add LSTM Layer\nmodel.add(LSTM(8, return_sequences = False))\n#Add Hidden Layer\nmodel.add(Dense(8, activation = \"leaky_relu\", kernel_regularizer = l2(0.01)))\n#Add output layer\nmodel.add(Dense(1, activation = \"linear\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:24:07.332549Z","iopub.execute_input":"2024-05-08T11:24:07.332946Z","iopub.status.idle":"2024-05-08T11:24:07.431996Z","shell.execute_reply.started":"2024-05-08T11:24:07.332914Z","shell.execute_reply":"2024-05-08T11:24:07.4308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_LSTM_model(\n                X:pd.DataFrame,\n                y: pd.Series,\n                X_test: pd.DataFrame,\n                y_test: pd.Series,\n                cv:TimeSeriesSplit,\n                model: tf.keras.models,\n                early_stopping: tf.keras.callbacks.EarlyStopping\n\n\n):\n    models = list()\n    test_preds = list()\n    fold_test_mse_scores = list()\n    elapsed_time = 0\n    histories = list()\n    for idx, (train_idx, val_idx) in enumerate(cv.split(X=X, y = y)):\n        start_time = time.time()\n\n        print(f\"train_idx: {train_idx}\")\n        print(f\"val_idx: {val_idx}\")\n\n        X_train = X[train_idx].copy()\n        y_train = y[train_idx].copy()\n        X_val = X[val_idx].copy()\n        y_val = y[val_idx].copy()\n\n\n        model.compile(\n            optimizer = Adam(learning_rate = 0.0001),\n            loss = \"mse\",\n            metrics = [MeanSquaredError]\n            \n        )\n        \n        history = model.fit(X_train, \n                            y_train, \n                            epochs = 200, \n                            batch_size = 32, \n                            validation_data = (X_val, y_val), \n                            callbacks = [early_stopping], \n                            verbose = 2\n                           )\n        \n        #Add history to list\n        histories.append(history)\n        \n        test_pred = model.predict(X_test)\n        test_pred = np.exp(standart_scaler.inverse_transform(test_pred))\n        test_preds.append(test_pred)\n        \n\n        fold_test_mse_score = mean_squared_error(y_true = y_test, y_pred = test_pred)\n        print(f\"\\nLSTM Model Fold {idx + 1} Mean Squred Error for Test Set:{fold_test_mse_score}\")\n        \n        fold_test_mse_scores.append(fold_test_mse_score)\n\n        #model_file_path = f\"{name}_fold_{idx + 1}.pkl\"\n        #joblib.dump(model, os.path.join(config.model_path, model_file_path))\n        models.append(model)\n\n        end_time = time.time()\n        elapsed = end_time - start_time\n        print(f\"Time to LSTM Model for Fold {idx + 1}: {elapsed}\")\n        print(\"*\"*120)\n\n        elapsed_time += elapsed\n        \n    print(f\"LSTM model run time is : {elapsed_time} seconds\")\n    print(f\"LSTM model has a mean of Mean Squared Error Score for Test Set: {np.mean(fold_test_mse_scores)}\")\n    print(\"*\"*120)\n\n    return fold_test_mse_scores, models, histories, test_preds\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T11:24:07.433217Z","iopub.execute_input":"2024-05-08T11:24:07.433529Z","iopub.status.idle":"2024-05-08T11:24:07.449279Z","shell.execute_reply.started":"2024-05-08T11:24:07.433501Z","shell.execute_reply":"2024-05-08T11:24:07.447982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_test_mse_scores_lstm, models_lstm, histories_lstm, test_preds_lstm = create_LSTM_model(X_train,\n                                                                                            y_train,\n                                                                                            X_test,\n                                                                                            y_test,\n                                                                                            cv = cv,\n                                                                                            model = model,\n                                                                                            early_stopping = early_stopping\n                                                                                            )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-08T11:24:07.450767Z","iopub.execute_input":"2024-05-08T11:24:07.452039Z","iopub.status.idle":"2024-05-08T12:16:55.275508Z","shell.execute_reply.started":"2024-05-08T11:24:07.452Z","shell.execute_reply":"2024-05-08T12:16:55.27425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 1, ncols = config.n_splits, figsize = (25, 6))\nfor i, history in enumerate(histories_lstm):\n    #Lineplot for train and validation loss\n    sns.lineplot(history.history[\"loss\"], label = \"Train\", color = \"blue\", ax = ax[i])\n    sns.lineplot(history.history[\"val_loss\"], label = \"Validation\", color = \"orange\", ax = ax[i])\n    \n    #Set title for graph\n    ax[i].set_title(f\"MSE Loss for Fold {i + 1} \", \n              fontsize = 15, \n              fontweight = 15)\n    #Set x_axis and y_axis label\n    ax[i].set_ylabel(\"MSE\")\n    ax[i].set_xlabel(\"Epochs\")\n\n#Display graph\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T12:16:55.277315Z","iopub.execute_input":"2024-05-08T12:16:55.278146Z","iopub.status.idle":"2024-05-08T12:16:56.867332Z","shell.execute_reply.started":"2024-05-08T12:16:55.278097Z","shell.execute_reply":"2024-05-08T12:16:56.865843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compared Models","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = config.n_splits, ncols = 1, figsize = (20, 5*config.n_splits))\n\nfor i in range(config.n_splits):\n    sns.lineplot(y_test, label = \"True\", color = \"blue\", ax = ax[i])\n    sns.lineplot(np.array(test_preds_lstm[i]).reshape(-1), label = \"Pred LSTM\", color = \"orange\", linestyle = \"--\", linewidth = 2, ax = ax[i])\n    sns.lineplot(np.array(test_preds_fcl[i]).reshape(-1), label = \"Pred Fully Connected Layer\", color = \"green\", linestyle = \"dotted\", ax = ax[i])\n    sns.lineplot(np.array(test_preds_xgb[i]).reshape(-1), label = \"Pred Xgboost\", color = \"red\", linestyle = \"dashdot\", ax = ax[i])\n    ax[i].set_title(f\"Fold {i+1} Preds vs True Values\", weight = \"bold\", fontsize = 10)\n    ax[i].legend()\n\nplt.show()\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T12:16:56.869399Z","iopub.execute_input":"2024-05-08T12:16:56.870284Z","iopub.status.idle":"2024-05-08T12:17:00.862363Z","shell.execute_reply.started":"2024-05-08T12:16:56.870237Z","shell.execute_reply":"2024-05-08T12:17:00.860428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dataframe to compared MSE Results\nlist_offold = [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\nlist_of_models = [\"XGB\", \"XGB\", \"XGB\", \"XGB\", \"XGB\", \n                  \"Fully Connected Layer\", \"Fully Connected Layer\", \"Fully Connected Layer\", \"Fully Connected Layer\", \"Fully Connected Layer\",\n                 \"LSTM\", \"LSTM\", \"LSTM\", \"LSTM\", \"LSTM\"]\nlist_of_mse_metrics = fold_test_mse_scores_xgb + fold_test_mse_scores_fcl + fold_test_mse_scores_lstm\n\na = pd.DataFrame(\n    {\n        \"Fold\": list_offold,\n        \"Model Name\": list_of_models,\n        \"MSE\": list_of_mse_metrics\n        \n        \n    }\n)\n\n#Create barplot to compare MSE Results of Models\nplt.figure(figsize = (15, 6))\nsns.barplot(a, x = \"Fold\", y = \"MSE\", hue = \"Model Name\")\nplt.title(\"Comparison of MSE Scores of Models for Test Set\")\n#plt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-08T12:17:00.86403Z","iopub.execute_input":"2024-05-08T12:17:00.864472Z","iopub.status.idle":"2024-05-08T12:17:01.359072Z","shell.execute_reply.started":"2024-05-08T12:17:00.864434Z","shell.execute_reply":"2024-05-08T12:17:01.357681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}